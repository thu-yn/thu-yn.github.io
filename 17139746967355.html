<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    Distributed Training - Prepare for the FUTURE
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Prepare for the FUTURE" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            Distributed Training   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/04/25</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_LLM.html'>#LLM</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <h2><a id="1%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1 通信原语</h2>
<h3><a id="broadcast" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>BroadCast</h3>
<p>节点将自己的数据原封不动的传给其他节点。</p>
<p><img src="media/17139746967355/17139747704066.jpg" alt="" /></p>
<p>通常用于LLM分布式训练时，网络参数的初始化。</p>
<h3><a id="scatter" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Scatter</h3>
<p>节点将自己的数据经过切片后分别传给其他节点。</p>
<p><img src="media/17139746967355/17139747923707.jpg" alt="" /></p>
<p>一般出现在数据并行的数据分配起步阶段。</p>
<h3><a id="gather" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gather</h3>
<p>多个节点将不同的数据发送给同一节点。</p>
<p><img src="media/17139746967355/17139747923707.jpg" alt="" /></p>
<p>Scatter的反过程。</p>
<h3><a id="reduce" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reduce</h3>
<p>一系列简单运算操作的简称。</p>
<p><img src="media/17139746967355/17139748827181.jpg" alt="" /></p>
<p>在每个节点上获取一个输入元素数组，经过操作后得到精简的更少的元素。</p>
<h3><a id="all-reduce" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>All Reduce</h3>
<p>单节点Reduce+Broadcast。</p>
<p><img src="media/17139746967355/17139748985902.jpg" alt="" /></p>
<h3><a id="all-gather" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>All Gather</h3>
<p><img src="media/17139746967355/17139749116417.jpg" alt="" /></p>
<h3><a id="all-2-all" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>All-2-All</h3>
<p>全交换操作：每个节点都可以向别的节点发送数据，也可以接收任意节点的数据。</p>
<p><img src="media/17139746967355/17139749646176.jpg" alt="" /></p>
<p>不同节点向某一节点收集到的数据不同（因为该节点的数据有很多，不像All Gather本来只有一个数据）</p>
<h2><a id="2%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2 数据并行</h2>
<h3><a id="2-1%E5%8E%9F%E5%9B%A0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1 原因</h3>
<p>单张GPU无法存储训练样本的数据。</p>
<h3><a id="2-2-dp-data-parallel" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2 DP: Data Parallel</h3>
<h4><a id="2-2-1%E5%9B%BE%E7%A4%BA" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.1 图示</h4>
<p><img src="media/17139746967355/17139750770189.jpg" alt="" /></p>
<h4><a id="2-2-2%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.2 线程通信</h4>
<p>只用于单机内部多块GPU通信，并不会跨机器节点进行通信。</p>
<h4><a id="2-2-3%E6%B5%81%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.3 流程</h4>
<p>将整个minibatch的数据加载到主线上，然后再将更小批次的sub-minibatches的数据分散到整个机器的各块GPU中进行计算：</p>
<p>主GPU（GPU1）负责持有模型，并且copy到其他的模型里，而且训练的mini-batch也是先给到GPU1，然后再通过Scatter的通信，将minibatch进一步打散成sub-minibatches，然后不同的sub-minibatches给到不同的GPU来进行训练处理。</p>
<ol>
<li>在前向计算时，每个GPU自己计算自己得这一部分数据，然后GPU1通过gather来收集所有的输出，再进行统一的损失计算；</li>
<li>把损失在 GPU 之间 scatter，在各个GPU之上运行后向传播，计算参数梯度；</li>
<li>在 GPU1 之上归并梯度，进而更新梯度参数，更新GPU1上的模型权重由于模型参数仅在GPU1上更新，而其他从属GPU此时并不是同步更新的，所以需要将更新后的模型参数复制到剩余的从属 GPU中，以此来实现并行。</li>
</ol>
<h4><a id="2-2-4%E7%BC%BA%E9%99%B7" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.4 缺陷</h4>
<p>通信局限性和低效性。</p>
<h3><a id="2-3-ddp-distributed-data-parallel" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.3 DDP: Distributed Data Parallel</h3>
<h4><a id="2-3-1%E5%9B%BE%E7%A4%BA" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.3.1 图示</h4>
<p><img src="media/17139746967355/17139751851761.jpg" alt="" /></p>
<h4><a id="2-3-2%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.3.2 进程通信</h4>
<p>不需要依赖某个GPU为主GPU。</p>
<ul>
<li>DDP每个GPU都拥有模型的一个副本，所以不需要拷贝模型。rank为0的进程会将网络初始化参数broadcast到其它每个进程中，确保每个进程中的模型都拥有一样的初始化值，广播的也只是模型的权重而不是模型本身，大大降低了跨节点拷贝的带宽。</li>
</ul>
<ol>
<li>加载数据阶段。DDP 不需要广播数据，而是使用多进程并行加载数据。在 host 之上，每个GPU的worker进程都会把自己负责的数据从硬盘load到显存。DistributedSampler 保证每个进程加载到的数据是彼此不重叠的。这样就免除了一次Scatter的操作，进一步提升了效率。</li>
<li>前向传播阶段。在每个GPU之上运行前向传播，计算输出。每个GPU都执行同样的训练，所以不需要有主 GPU。计算损失，也都是在每个GPU之上独立计算损失。</li>
<li>反向传播阶段。运行后向传播来计算梯度，在计算梯度同时也对梯度执行all-reduce操作。</li>
<li>更新模型参数阶段。因为每个GPU都从完全相同的模型开始训练，并且梯度被all-reduced，因此每个GPU在反向传播结束时最终得到平均梯度的相同副本，所有GPU上的权重更新都相同，也就不需要模型同步了，又比DP节省了不少的带宽和时间。</li>
</ol>
<h2><a id="3%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3 模型并行</h2>
<h3><a id="3-1%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 产生原因</h3>
<p>单张GPU无法存储模型的完整参数。</p>
<h3><a id="3-2-pp-pipeline-parallel" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 PP: Pipeline Parallel</h3>
<h4><a id="3-2-1%E4%BC%A0%E7%BB%9F" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.1 传统</h4>
<p><img src="media/17139746967355/17139753163586.jpg" alt="" /></p>
<p>此时同一时刻只有一个GPU在工作，造成极大的算力浪费。</p>
<p><img src="media/17139746967355/17139753251391.jpg" alt="" /></p>
<p>把一个参数量较大的模型按照不同的层进行划分，将多个模型的层尽可能均匀的分布在不同的GPU显存上，来起到装载更大模型的能力。</p>
<h4><a id="3-2-2%E6%94%B9%E8%BF%9B%EF%BC%9A-gpipe%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.2 改进：Gpipe流水线并行</h4>
<p><img src="media/17139746967355/17139753797905.jpg" alt="" /></p>
<p>把一个Mini-bacth，拆解成更小的Micro-batches<br />
。</p>
<p>当F1也就是前向计算的第一个Micro-batch1被GPU0计算完毕，它就会传递到模型的下一层GPU1，然后GPU0可以继续计算Micro-batch2,以此类推，在同一个计算时间内，尽可能的压榨算力获得更高的性能。</p>
<h4><a id="3-2-3%E6%94%B9%E8%BF%9B%EF%BC%9A-1f1b" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.3 改进：1F1B</h4>
<p><img src="media/17139746967355/17139754284000.jpg" alt="" /></p>
<blockquote>
<p>也要注意多版本控制，防止传播时采用的权重错误。</p>
</blockquote>
<h3><a id="3-3-tp-tensor-parallel" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3 TP: Tensor Parallel</h3>
<h4><a id="3-3-1%E5%9B%BE%E7%A4%BA" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.1 图示</h4>
<p><img src="media/17139746967355/17139754734656.jpg" alt="" /></p>
<p>基本思想：将模型的参数纵向切开，放到不同的GPU上进行独立计算，最后在做聚合。</p>
<h4><a id="3-3-2%E8%A6%81%E6%B1%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3.2 要求</h4>
<ul>
<li>算子具有可以并行的条件，比如MatMul或者矩阵点乘；</li>
<li>算子中其中一个输入来自于parameter。</li>
</ul>
<h2><a id="4%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4 内存优化</h2>
<h3><a id="4-1%E9%87%8D%E8%AE%A1%E7%AE%97" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1 重计算</h3>
<h4><a id="4-1-1%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1.1 产生原因</h4>
<p>模型训练需要反向传播，其中会用到正向传播中很多的中间量，因此通常模型会将需要用到的中间量在前向传播时持续保留，直到反向传播时再将其调用，这会占用很大的内存。</p>
<h4><a id="4-1-2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1.2 解决方法</h4>
<p>不保留前向传播中需要在后端被用到的参数，而是在后端是重新对其进行计算。</p>
<h4><a id="4-1-3%E6%9C%AC%E8%B4%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1.3 本质</h4>
<ul>
<li>时间换空间。</li>
</ul>
<h4><a id="4-1-4%E5%9B%BE%E7%A4%BA" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1.4 图示</h4>
<p><img src="media/17139746967355/17139755850791.jpg" alt="" /></p>
<h3><a id="4-2%E4%BC%98%E5%8C%96%E5%99%A8%E4%BC%98%E5%8C%96-zero" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.2 优化器优化ZERO</h3>
<h4><a id="4-2-1%E5%9B%BE%E7%A4%BA" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.2.1 图示</h4>
<p><img src="media/17139746967355/17139756100193.jpg" alt="" /></p>
<h4><a id="4-2-2%E8%BF%87%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.2.2 过程</h4>
<ul>
<li>优化器状态切分：切分优化器状态到各个计算卡中，在享有与普通数据并行相同通信量的情况下，可降低4倍的内存占用；</li>
<li>梯度拆分：在优化器状态切分的基础上，进一步将模型梯度切分到各个计算卡中，在享有与普通数据并行相同通信量的情况下，拥有8倍的内存降低能力；</li>
<li>参数切分：在梯度拆分的基础上，将模型参数也切分到各个计算卡中，内存降低能力与并行数量成线性比例，通信量大约有50%的增长。</li>
</ul>
<h3><a id="4-3%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.3 混合精度训练</h3>
<h4><a id="4-3-1%E6%80%9D%E6%83%B3" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.3.1 思想</h4>
<p>采用半精度浮点数float16代替一些全精度浮点数float32的操作，节约内存，计算速度变快。</p>
<h4><a id="4-3-2%E9%97%AE%E9%A2%98-1" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.3.2 问题1</h4>
<p>数据溢出：fp16的动态范围远远小于fp32的，很容易出现数据的下溢出，造成值为0的错误。</p>
<p>解决方法——Loss Scale：对计算出来的Loss乘以一个尺度因子scale，使其变大到能让fp16正确表示，在最终传播中再除以该scale，恢复出正确的梯度。</p>
<h4><a id="4-3-2%E9%97%AE%E9%A2%98-2" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.3.2 问题2</h4>
<p>舍入误差：fp16在相加过程中，若某个加数小于当前数量级的最小间隔，则会导致出现加法错误，该加数会被抹掉。</p>
<p>解决方法：</p>
<ul>
<li>权重备份：将所有待更新的参数都用fp32进行额外备份，采用fp16进行计算，但在最后参数更新时，使用fp32对fp16得到的结果进行参数更新，防止舍入误差。</li>
<li>提高算数精度：用fp16进行矩阵乘法和存储，用fp32进行加法计算。</li>
</ul>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style>


  
    




  </body>
</html>
