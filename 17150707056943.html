<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    LoReFT-Llama3-8B-Base-Code-122k - Prepare for the FUTURE
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Prepare for the FUTURE" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            LoReFT-Llama3-8B-Base-Code-122k   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/05/07</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_Llama3%20ReFTEng%20vs%20PEFT.html'>#Llama3 ReFTEng vs PEFT</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <blockquote>
<p>è‡ªä» llama3-8b-base çš„ commonsense å¾®è°ƒè·‘é€šä¹‹åï¼Œå¯¹äº base å’Œ instruct çš„æ¨¡å‹çš„ commonsense æˆ– math å¾®è°ƒå°±åªæ˜¯æ—¶é—´é—®é¢˜ã€‚å› æ­¤å°†ç›®æ ‡æ”¾åœ¨åˆ©ç”¨ ReFT å®ç° llama3-8b åœ¨ code ä»»åŠ¡ä¸Šçš„å¾®è°ƒã€‚</p>
</blockquote>
<h2><a id="prepare" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prepare</h2>
<p>å…·ä½“å¯ä»¥å‚è€ƒä¹‹å‰çš„åšå®¢ <a href="https://thu-yn.github.io/17147464283285.html" title="LoReFT-Llama3-8B-Base-Commonsense-170k">LoReFT-Llama3-8B-Base-Commonsense-170k</a> çš„ç›¸å…³é…ç½®ã€‚</p>
<h2><a id="dataset" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset</h2>
<p>ç”±äºç¼ºä¹å¯¹åº”çš„ train&amp;eval æ•°æ®é›†ï¼Œå› æ­¤éœ€è¦è‡ªå·±å»æ‰¾å¼€æºçš„æ•°æ®é›†ã€‚</p>
<h3><a id="train-dataset" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train Dataset</h3>
<p>åœ¨è®­ç»ƒæ•°æ®é›†æ–¹é¢ï¼Œé€‰æ‹© hugging face ä¸Šçš„ <a href="https://huggingface.co/datasets/TokenBender/code_instructions_122k_alpaca_style" title="TokenBender/code_instructions_122k_alpaca_style">code_instructions_122k_alpaca_style</a> æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†é‡‡ç”¨ç»å…¸çš„ alpaca æ ¼å¼è¿›è¡Œ promptã€‚é¦–å…ˆå°†å…¶ä¸‹è½½åˆ°æœ¬åœ°å¹¶æ”¹åï¼š</p>
<pre><code class="language-shell"># é»˜è®¤å·²ç»è¿›å…¥ LoReFT è™šæ‹Ÿç¯å¢ƒï¼Œå¹¶è¿›å…¥åˆ° /root/auto-tmp/pyreft/examples/loreft ä¸­
# åˆ›å»ºæ–‡ä»¶å¤¹
cd dataset &amp;&amp; mkdir code_122k &amp;&amp; cd code_122k

# ä¸‹è½½æ•°æ®é›†ï¼ˆç”¨ hf-mirror.com æ›´å¿«ï¼‰
# æ³¨ï¼šä¸‹è½½é“¾æ¥ï¼šå°†é¼ æ ‡æ”¾åœ¨æ•°æ®é›†ä¸Šï¼Œå³é”®å¤åˆ¶é“¾æ¥ã€‚
wget https://hf-mirror.com/datasets/TokenBender/code_instructions_122k_alpaca_style/resolve/main/code_instructions_120k.json?download=true

--2024-05-07 16:25:03--  https://cdn-lfs.hf-mirror.com/repos/ab/1d/***&amp;response-content-type=***&amp;Expires=***&amp;Policy=***&amp;Signature=***&amp;Key-Pair-Id=***
Resolving cdn-lfs.hf-mirror.com (cdn-lfs.hf-mirror.com)... *.*.*.*, *.*.*.*, *.*.*.*, ...
Connecting to cdn-lfs.hf-mirror.com (cdn-lfs.hf-mirror.com)|*.*.*.*|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 169499006 (162M) [application/json]
Saving to: â€˜code_instructions_120k.json?download=trueâ€™

code_instruction 100%[========&gt;] 161.65M  16.9MB/s    in 9.7s    

# æ”¹åï¼ˆå³é”®ä¹Ÿå¯ä»¥ï¼‰
mv code_instructions_120k.json\?download\=true train.json

# æ£€æŸ¥
ls
train.json
</code></pre>
<p><br />
æ¥ä¸‹æ¥è¾“å‡ºå…¶ä¸­ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œè§‚å¯Ÿå…¶ç‰¹å¾ï¼š</p>
<pre><code class="language-python"># åœ¨ /root/auto-tmp/pyreft/examples/loreft/dataset/code_122k ä¸‹

&gt;&gt;&gt; from datasets import load_dataset
&gt;&gt;&gt; dataset = load_dataset(&quot;json&quot;, data_files=&quot;train.json&quot;, split=&quot;train&quot;)
Generating train split: 121959 examples [00:01, 96800.40 examples/Generating train split: 121959 examples [00:01, 92617.72 examples/s]
&gt;&gt;&gt; dataset[0]
{'output': '# Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum', 'input': '[1, 2, 3, 4, 5]', 'instruction': 'Create a function to calculate the sum of a sequence of integers.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: Create a function to calculate the sum of a sequence of integers. ### Input: [1, 2, 3, 4, 5] ### Output: # Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum'}
</code></pre>
<p><br />
å¯ä»¥çœ‹åˆ°ï¼Œå…¶æ ·æœ¬æŒ‰ç…§ä»¥ä¸‹è¡¨æ ¼å½¢å¼åˆ†å¸ƒï¼š</p>
<table>
<thead>
<tr>
<th>instruction</th>
<th style="text-align: left">input</th>
<th>output</th>
<th>text</th>
</tr>
</thead>
<tbody>
<tr>
<td>Create a function to calculate the sum of a sequence of integers.</td>
<td style="text-align: left">[1, 2, 3, 4, 5]</td>
<td># Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum</td>
<td>Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: Create a function to calculate the sum of a sequence of integers. ### Input: [1, 2, 3, 4, 5] ### Output: # Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum</td>
</tr>
</tbody>
</table>
<p>åœ¨ <code>/loreft/templates.py</code> å†…æ‰¾åˆ°å¯¹åº”çš„æ¨¡ç‰ˆ <code>alpaca_prompt_template</code>ï¼ŒåŒæ—¶æ³¨æ„åˆ°æŸäº› inpur æ˜¯ç©ºçš„ï¼Œå› æ­¤éœ€è¦ç›¸åº”çš„ <code>alpaca_prompt_no_input_template</code>ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<pre><code class="language-python">alpaca_prompt_template = &quot;&quot;&quot;Below is an instruction that \
describes a task, paired with an input that provides \
further context. Write a response that appropriately \
completes the request.

### Instruction:
%s

### Input:
%s

### Response:
&quot;&quot;&quot;

alpaca_prompt_no_input_template = &quot;&quot;&quot;Below is an instruction that \
describes a task. Write a response that appropriately \
completes the request.

### Instruction:
%s

### Response:
&quot;&quot;&quot;
</code></pre>
<h3><a id="eval-dataset" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Eval Dataset</h3>
<p><del>åœ¨éªŒè¯æ•°æ®é›†ä¸Šï¼Œé‡‡ç”¨ <a href="https://github.com/openai/human-eval" title="human-eval">Human-Eval</a> å’Œ<a href="https://github.com/google-research/google-research/tree/master/mbpp" title="mbpp">MBPP</a>å…±åŒä½œä¸ºè¯„åˆ†çš„æŒ‡æ ‡ã€‚</del><br />
é‡‡ç”¨ <a href="https://github.com/bigcode-project/bigcode-evaluation-harness" title="bigcode-evaluation-harness">bigcode-evaluation-harness</a> æ¥è¿›è¡Œå„ä¸ªæŒ‡æ ‡çš„è¯„ä¼°ã€‚</p>
<h4><a id="human-eval" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Human-Eval</h4>
<p>é¦–å…ˆæ˜¯ Human-Eval æ•°æ®é›†ï¼Œå°†å…¶ git åˆ° <code>/root/auto-tmp/</code> è·¯å¾„ä¸‹ï¼Œå¹¶å®‰è£…ç›¸å…³åŒ…ï¼š</p>
<pre><code class="language-shell"># åŒæ ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸‹
cd /root/auto-tmp

# git
git clone https://github.com/openai/human-eval

# installation
/root/miniconda3/envs/LoReFT/bin/pip install -e human-eval

Looking in indexes: http://mirrors.aliyun.com/pypi/simple
Obtaining file:///root/autodl-tmp/human-eval
  Preparing metadata (setup.py) ... done
Requirement already satisfied: tqdm in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from human-eval==1.0) (4.66.4)
Requirement already satisfied: fire in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from human-eval==1.0) (0.6.0)
Requirement already satisfied: numpy in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from human-eval==1.0) (1.26.4)
Requirement already satisfied: six in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from fire-&gt;human-eval==1.0) (1.16.0)
Requirement already satisfied: termcolor in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from fire-&gt;human-eval==1.0) (2.4.0)
Installing collected packages: human-eval
  Running setup.py develop for human-eval
Successfully installed human-eval-1.0
</code></pre>
<p><br />
å¯ä»¥çœ‹åˆ°å…¶é‡‡å–çš„è¯„ä¼°æ ·æœ¬çš„ç¤ºä¾‹ï¼ˆåœ¨ <code>human-eval/data/HumanEval.jsonl.gz</code> ä¸­ï¼‰ï¼š</p>
<pre><code class="language-python">{&quot;task_id&quot;: &quot;HumanEval/0&quot;, &quot;prompt&quot;: &quot;from typing import List\n\n\ndef has_close_elements(numbers: List[float], threshold: float)-&gt; bool:\n    \&quot;\&quot;\&quot; Check if in given list of numbers, are any two numbers closer to each other than\n    given threshold.\n    &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n    True\n    \&quot;\&quot;\&quot;\n&quot;, &quot;entry_point&quot;: &quot;has_close_elements&quot;, &quot;canonical_solution&quot;: &quot;for idx, elem in enumerate(numbers):\n        for idx2, elem2 in enumerate(numbers):\n            if idx != idx2:\n                distance = abs(elem - elem2)\n                if distance &lt; threshold:\n                    return True\n\n    return False\n&quot;, &quot;test&quot;: &quot;\n\nMETADATA = {\n'author':'jt',\n'dataset':'test'\n}\n\n\ndef check(candidate):\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3)== True\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05)== False\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95)== True\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8)== False\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1)== True\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0)== True\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5)== False\n\n&quot;}
</code></pre>
<p><br />
é€šè¿‡äº†è§£å¾—çŸ¥ï¼Œhuman-eval ä¸€å…±åªæœ‰ 164 æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆï¼š</p>
<pre><code class="language-shell">â”œâ”€â”€ example
â”‚   â”œâ”€â”€ task_idï¼šä»»åŠ¡ id
â”‚   â”œâ”€â”€ promptï¼š é¢˜ç›®
â”‚   â”œâ”€â”€ entry_pointï¼šå”¯ä¸€æ ‡è®°
â”‚   â”œâ”€â”€ canonical_solutionï¼šå‚è€ƒç­”æ¡ˆ
â”‚   â”œâ”€â”€ testï¼šæµ‹è¯•ç”¨ä¾‹
</code></pre>
<p><br />
è‹¥æƒ³å¯¹ç”Ÿæˆæ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œåˆ™åªéœ€è¦ä¸¤æ­¥ï¼š</p>
<ul>
<li>å®šä¹‰ <code>generate_one_completion</code> å‡½æ•°ï¼Œå…¶ä½œç”¨æ˜¯è°ƒç”¨å½“å‰å¾®è°ƒåçš„å¤§æ¨¡å‹å¯¹æµ‹è¯•ç”¨ä¾‹ä¸­çš„æ¯ä¸ªæ ·æœ¬çš„ prompt è¿›è¡Œä»£ç ç”Ÿæˆã€‚</li>
</ul>
<pre><code class="language-python">from human_eval.data import write_jsonl, read_problems

problems = read_problems()

num_samples_per_task = 200
samples = [dict(task_id=task_id, completion=generate_one_completion(problems[task_id][&quot;prompt&quot;]))
    for task_id in problems
    for _ in range(num_samples_per_task)
]
write_jsonl(&quot;samples.jsonl&quot;, samples)
</code></pre>
<ul>
<li>è°ƒç”¨ <code>evaluate_functional_correctness</code> å¯¹ä¸Šä¸€æ­¥ç”Ÿæˆçš„ <code>&quot;samples.jsonl&quot;</code> è¿›è¡Œè¯„ä¼°ï¼š</li>
</ul>
<pre><code class="language-shell">evaluate_functional_correctness samples.jsonl
</code></pre>
<h4><a id="bigcode-evaluation-harness" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>bigcode-evaluation-harness</h4>
<p>è¿™æ˜¯ä¸€ä¸ªå¼€æºçš„ github åº“ï¼Œç”¨äºè¯„ä¼°ä»£ç ç”Ÿæˆæ¨¡å‹çš„æ¡†æ¶ã€‚ä¸€å…±æœ‰ 7 ä¸ªä»£ç ç”Ÿæˆä»»åŠ¡ã€‚</p>
<pre><code class="language-shell"># åŒæ ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸‹
cd /root/auto-tmp

# git
git clone https://github.com/bigcode-project/bigcode-evaluation-harness.git

# installation
/root/miniconda3/envs/LoReFT/bin/pip install -e bigcode-evaluation-harness
</code></pre>
<p><br />
ç„¶è€Œå´æŠ¥é”™ï¼š</p>
<pre><code class="language-shell">Looking in indexes: http://mirrors.aliyun.com/pypi/simple
Obtaining file:///root/autodl-tmp/bigcode-evaluation-harness
  Preparing metadata (setup.py) ... done
Requirement already satisfied: transformers&gt;=4.25.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from bigcode-eval==0.0.0) (4.40.1)
Requirement already satisfied: accelerate&gt;=0.13.2 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from bigcode-eval==0.0.0) (0.29.3)
Requirement already satisfied: datasets&gt;=2.6.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from bigcode-eval==0.0.0) (2.18.0)
Requirement already satisfied: evaluate&gt;=0.3.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from bigcode-eval==0.0.0) (0.4.2)
Collecting pyext==0.7 (from bigcode-eval==0.0.0)
  Downloading http://mirrors.aliyun.com/pypi/packages/b0/be/9b6005ac644aaef022527ce49617263379e49dbdbd433d1d3dd66d71f570/pyext-0.7.tar.gz (7.8 kB)
  Preparing metadata (setup.py) ... done
Collecting mosestokenizer==1.0.0 (from bigcode-eval==0.0.0)
  Downloading http://mirrors.aliyun.com/pypi/packages/45/c6/913c968e5cbcaff6cdd2a54a1008330c01a573ecadcdf9f526058e3d33a0/mosestokenizer-1.0.0-py3-none-any.whl (51 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 51.2/51.2 kB 2.5 MB/s eta 0:00:00
Requirement already satisfied: huggingface_hub&gt;=0.11.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from bigcode-eval==0.0.0) (0.20.3)
Collecting fsspec&lt;2023.10.0 (from bigcode-eval==0.0.0)
  Downloading http://mirrors.aliyun.com/pypi/packages/fe/d3/e1aa96437d944fbb9cc95d0316e25583886e9cd9e6adc07baad943524eda/fsspec-2023.9.2-py3-none-any.whl (173 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 173.4/173.4 kB 7.0 MB/s eta 0:00:00
Collecting docopt (from mosestokenizer==1.0.0-&gt;bigcode-eval==0.0.0)
  Downloading http://mirrors.aliyun.com/pypi/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz (25 kB)
  Preparing metadata (setup.py) ... done
Collecting openfile (from mosestokenizer==1.0.0-&gt;bigcode-eval==0.0.0)
  Downloading http://mirrors.aliyun.com/pypi/packages/93/e6/805db6867faacb488b44ba8e0829ef4de151dd0499f3c5da5f4ad11698a7/openfile-0.0.7-py3-none-any.whl (2.4 kB)
Collecting toolwrapper (from mosestokenizer==1.0.0-&gt;bigcode-eval==0.0.0)
  Downloading http://mirrors.aliyun.com/pypi/packages/41/7b/34bf8fb69426d8a18bcc61081e9d126f4fcd41c3c832072bef39af1602cd/toolwrapper-2.1.0.tar.gz (3.2 kB)
  Preparing metadata (setup.py) ... done
Requirement already satisfied: numpy&gt;=1.17 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (1.26.4)
Requirement already satisfied: packaging&gt;=20.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (24.0)
Requirement already satisfied: psutil in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (5.9.8)
Requirement already satisfied: pyyaml in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (6.0.1)
Requirement already satisfied: torch&gt;=1.10.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (2.1.0+cu118)
Requirement already satisfied: safetensors&gt;=0.3.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (0.4.3)
Requirement already satisfied: filelock in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (3.13.1)
Requirement already satisfied: pyarrow&gt;=12.0.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (16.0.0)
Requirement already satisfied: pyarrow-hotfix in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (0.6)
Requirement already satisfied: dill&lt;0.3.9,&gt;=0.3.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (0.3.8)
Requirement already satisfied: pandas in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2.2.2)
Requirement already satisfied: requests&gt;=2.19.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2.31.0)
Requirement already satisfied: tqdm&gt;=4.62.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (4.66.4)
Requirement already satisfied: xxhash in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (3.4.1)
Requirement already satisfied: multiprocess in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (0.70.16)
Requirement already satisfied: aiohttp in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (3.9.5)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from huggingface_hub&gt;=0.11.1-&gt;bigcode-eval==0.0.0) (4.11.0)
Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from transformers&gt;=4.25.1-&gt;bigcode-eval==0.0.0) (2024.4.28)
Requirement already satisfied: tokenizers&lt;0.20,&gt;=0.19 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from transformers&gt;=4.25.1-&gt;bigcode-eval==0.0.0) (0.19.1)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from aiohttp-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (1.3.1)
Requirement already satisfied: attrs&gt;=17.3.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from aiohttp-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (23.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from aiohttp-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (1.4.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from aiohttp-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (6.0.5)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from aiohttp-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (1.9.4)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from aiohttp-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (4.0.3)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from requests&gt;=2.19.0-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2.1.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from requests&gt;=2.19.0-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from requests&gt;=2.19.0-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (1.26.13)
Requirement already satisfied: certifi&gt;=2017.4.17 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from requests&gt;=2.19.0-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2022.12.7)
Requirement already satisfied: sympy in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from torch&gt;=1.10.0-&gt;accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (1.12)
Requirement already satisfied: networkx in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from torch&gt;=1.10.0-&gt;accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (3.2.1)
Requirement already satisfied: jinja2 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from torch&gt;=1.10.0-&gt;accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (3.1.3)
Requirement already satisfied: triton==2.1.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from torch&gt;=1.10.0-&gt;accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (2.1.0)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from pandas-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from pandas-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from pandas-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (2024.1)
Requirement already satisfied: six&gt;=1.5 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets&gt;=2.6.1-&gt;bigcode-eval==0.0.0) (1.16.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from jinja2-&gt;torch&gt;=1.10.0-&gt;accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (2.1.5)
Requirement already satisfied: mpmath&gt;=0.19 in /root/miniconda3/envs/LoReFT/lib/python3.9/site-packages (from sympy-&gt;torch&gt;=1.10.0-&gt;accelerate&gt;=0.13.2-&gt;bigcode-eval==0.0.0) (1.3.0)
Building wheels for collected packages: pyext, docopt, toolwrapper
  Building wheel for pyext (setup.py) ... done
  Created wheel for pyext: filename=pyext-0.7-py3-none-any.whl size=7220 sha256=994385fc51239f3e8d82ca21b8a3152bf873f832e6674ea3279ad1c3d91f5695
  Stored in directory: /root/.cache/pip/wheels/ec/9f/a2/3c50fa0f513c656523a3724295f8fb37c5f09572774be10570
  Building wheel for docopt (setup.py) ... done
  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=b4fd6997789d860074a28b0c07dd98c58a140d51772496452e0e381582202ad4
  Stored in directory: /root/.cache/pip/wheels/74/2f/07/7824901723b560c9c8114388098d86bd51f940c34590d6fc9d
  Building wheel for toolwrapper (setup.py) ... done
  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3337 sha256=e31b2a9a94ac66dde5bca830e2501efd620542b9ec5e285a1a640a34e6566dac
  Stored in directory: /root/.cache/pip/wheels/5b/11/5e/a30eaffc02989a636edaaf1f336808e521019cd739756366e1
Successfully built pyext docopt toolwrapper
Installing collected packages: toolwrapper, pyext, openfile, docopt, mosestokenizer, fsspec, bigcode-eval
  Attempting uninstall: fsspec
    Found existing installation: fsspec 2024.2.0
    Uninstalling fsspec-2024.2.0:
      Successfully uninstalled fsspec-2024.2.0
  Running setup.py develop for bigcode-eval
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
gcsfs 2024.2.0 requires fsspec==2024.2.0, but you have fsspec 2023.9.2 which is incompatible.
pyreft 0.0.5 requires fsspec&gt;=2024.2.0, but you have fsspec 2023.9.2 which is incompatible.
Successfully installed bigcode-eval-0.0.0 docopt-0.6.2 fsspec-2023.9.2 mosestokenizer-1.0.0 openfile-0.0.7 pyext-0.7 toolwrapper-2.1.0
</code></pre>
<p><br />
å¯ä»¥çœ‹åˆ° bigcode-evaluation-harness å’Œ pyreft æ‰€éœ€è¦çš„å…±åŒåº“ <code>fsspec</code> å‘ç”Ÿäº†ç‰ˆæœ¬å†²çªï¼Œå› æ­¤è€ƒè™‘æ–°å¼€ä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œå®‰è£… bigcode-evaluation-harnessã€‚</p>
<blockquote>
<p>æ³¨ï¼šåœ¨ bigcode-evaluation-harness çš„ README.md ä¸­ï¼ŒæŒ‡å‡ºè¦è¿›è¡Œ <code>DS-1000</code> çš„æŒ‡æ ‡è¯„ä¼°ï¼Œéœ€è¦ <code>python==3.7.10</code> å’Œ <code>torch==1.12.1</code>ã€‚</p>
</blockquote>
<pre><code class="language-shell"># æ–°å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n &quot;CodeEval&quot; python=3.7

cd /root/auto-tmp/bigcode-evaluation-harness

# installation
# æ³¨ï¼šåœ¨è¿™è¡Œè¯¥å‘½ä»¤æ—¶ï¼Œä¼šè‡ªåŠ¨å®‰è£… 1.12.1 ç‰ˆæœ¬çš„ torchï¼Œä½†æ˜¯éœ€è¦å¸è½½æ‰å®ƒï¼Œç„¶åé‡æ–°å®‰è£… 1.12.1+cu116 ç‰ˆæœ¬çš„ torchã€‚
/root/miniconda3/envs/CodeEval/bin/pip install -e &quot;.[ds1000]&quot;

# uninstall torch
/root/miniconda3/envs/CodeEval/bin/pip uninstall torch

# install pytorch
/root/miniconda3/envs/CodeEval/bin/pip install torch==1.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116

# æŸ¥çœ‹å®‰è£…çš„åº“
conda list

# packages in environment at /root/miniconda3/envs/CodeEval:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
_openmp_mutex             5.1                       1_gnu    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
absl-py                   2.1.0                    pypi_0    pypi
accelerate                0.20.3                   pypi_0    pypi
aiohttp                   3.8.6                    pypi_0    pypi
aiosignal                 1.3.1                    pypi_0    pypi
astunparse                1.6.3                    pypi_0    pypi
async-timeout             4.0.3                    pypi_0    pypi
asynctest                 0.13.0                   pypi_0    pypi
attrs                     23.2.0                   pypi_0    pypi
bigcode-eval              0.0.0                     dev_0    &lt;develop&gt;
ca-certificates           2024.3.11            h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
cachetools                5.3.3                    pypi_0    pypi
certifi                   2022.12.7        py37h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
charset-normalizer        3.3.2                    pypi_0    pypi
cycler                    0.11.0                   pypi_0    pypi
datasets                  2.13.2                   pypi_0    pypi
datetime                  4.7                      pypi_0    pypi
dill                      0.3.6                    pypi_0    pypi
docopt                    0.6.2                    pypi_0    pypi
et-xmlfile                1.1.0                    pypi_0    pypi
evaluate                  0.4.1                    pypi_0    pypi
filelock                  3.12.2                   pypi_0    pypi
flatbuffers               24.3.25                  pypi_0    pypi
fonttools                 4.38.0                   pypi_0    pypi
frozenlist                1.3.3                    pypi_0    pypi
fsspec                    2023.1.0                 pypi_0    pypi
gast                      0.4.0                    pypi_0    pypi
gensim                    4.2.0                    pypi_0    pypi
google-auth               2.29.0                   pypi_0    pypi
google-auth-oauthlib      0.4.6                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.62.2                   pypi_0    pypi
h5py                      3.8.0                    pypi_0    pypi
huggingface-hub           0.16.4                   pypi_0    pypi
idna                      3.7                      pypi_0    pypi
importlib-metadata        6.7.0                    pypi_0    pypi
joblib                    1.3.2                    pypi_0    pypi
keras                     2.10.0                   pypi_0    pypi
keras-preprocessing       1.1.2                    pypi_0    pypi
kiwisolver                1.4.5                    pypi_0    pypi
ld_impl_linux-64          2.38                 h1181459_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libclang                  18.1.1                   pypi_0    pypi
libffi                    3.4.4                h6a678d5_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libgcc-ng                 11.2.0               h1234567_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libgomp                   11.2.0               h1234567_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libstdcxx-ng              11.2.0               h1234567_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
lxml                      5.2.1                    pypi_0    pypi
markdown                  3.4.4                    pypi_0    pypi
markupsafe                2.1.5                    pypi_0    pypi
matplotlib                3.5.2                    pypi_0    pypi
mosestokenizer            1.0.0                    pypi_0    pypi
multidict                 6.0.5                    pypi_0    pypi
multiprocess              0.70.14                  pypi_0    pypi
ncurses                   6.4                  h6a678d5_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
numpy                     1.21.6                   pypi_0    pypi
oauthlib                  3.2.2                    pypi_0    pypi
openai                    0.23.0                   pypi_0    pypi
openfile                  0.0.7                    pypi_0    pypi
openpyxl                  3.1.2                    pypi_0    pypi
openssl                   1.1.1w               h7f8727e_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
opt-einsum                3.3.0                    pypi_0    pypi
packaging                 24.0                     pypi_0    pypi
pandas                    1.3.5                    pypi_0    pypi
pandas-datareader         0.10.0                   pypi_0    pypi
pandas-stubs              1.2.0.62                 pypi_0    pypi
pathlib                   1.0.1                    pypi_0    pypi
patsy                     0.5.6                    pypi_0    pypi
pillow                    9.2.0                    pypi_0    pypi
pip                       22.3.1           py37h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
protobuf                  3.19.6                   pypi_0    pypi
psutil                    5.9.8                    pypi_0    pypi
pyarrow                   12.0.1                   pypi_0    pypi
pyasn1                    0.5.1                    pypi_0    pypi
pyasn1-modules            0.3.0                    pypi_0    pypi
pyext                     0.7                      pypi_0    pypi
pyparsing                 3.1.2                    pypi_0    pypi
python                    3.7.16               h7a1cb2a_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
python-dateutil           2.9.0.post0              pypi_0    pypi
pytz                      2024.1                   pypi_0    pypi
pyyaml                    6.0.1                    pypi_0    pypi
readline                  8.2                  h5eee18b_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
regex                     2024.4.16                pypi_0    pypi
requests                  2.31.0                   pypi_0    pypi
requests-oauthlib         2.0.0                    pypi_0    pypi
responses                 0.18.0                   pypi_0    pypi
rsa                       4.9                      pypi_0    pypi
safetensors               0.4.3                    pypi_0    pypi
scikit-learn              1.0.2                    pypi_0    pypi
scipy                     1.7.3                    pypi_0    pypi
seaborn                   0.11.2                   pypi_0    pypi
setuptools                65.6.3           py37h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
six                       1.16.0                   pypi_0    pypi
smart-open                7.0.4                    pypi_0    pypi
sqlite                    3.45.3               h5eee18b_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
statsmodels               0.13.2                   pypi_0    pypi
tensorboard               2.10.1                   pypi_0    pypi
tensorboard-data-server   0.6.1                    pypi_0    pypi
tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
tensorflow                2.10.0                   pypi_0    pypi
tensorflow-estimator      2.10.0                   pypi_0    pypi
tensorflow-io-gcs-filesystem 0.34.0                   pypi_0    pypi
termcolor                 2.3.0                    pypi_0    pypi
threadpoolctl             3.1.0                    pypi_0    pypi
tk                        8.6.14               h39e8969_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
tokenizers                0.12.1                   pypi_0    pypi
toolwrapper               2.1.0                    pypi_0    pypi
torch                     1.12.1+cu116           pypi_0    pypi
torchvision               0.13.1                   pypi_0    pypi
tqdm                      4.64.1                   pypi_0    pypi
transformers              4.30.2                   pypi_0    pypi
typing-extensions         4.7.1                    pypi_0    pypi
urllib3                   2.0.7                    pypi_0    pypi
werkzeug                  2.2.3                    pypi_0    pypi
wheel                     0.38.4           py37h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
wrapt                     1.16.0                   pypi_0    pypi
xgboost                   1.6.2                    pypi_0    pypi
xxhash                    3.4.1                    pypi_0    pypi
xz                        5.4.6                h5eee18b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
yarl                      1.9.4                    pypi_0    pypi
zipp                      3.15.0                   pypi_0    pypi
zlib                      1.2.13               h5eee18b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
zope-interface            6.3                      pypi_0    pypi
</code></pre>
<p><br />
åˆ°æ—¶å€™æˆ‘ä»¬å°†å¾®è°ƒå¥½çš„æ¨¡å‹åœ¨ <code>CodeEval</code> ç¯å¢ƒä¸­è¿›è¡ŒæŒ‡æ ‡è¯„ä¼°å³å¯ã€‚</p>
<h2><a id="modify" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modify</h2>
<p>æœ¬èŠ‚è¦æ²¿ç€ train.py é€æ­¥æ¨è¿›ï¼Œå¯¹å¯èƒ½è¿›è¡Œä¿®æ”¹çš„åœ°æ–¹è¿›è¡Œä¿®æ”¹ã€‚</p>
<h3><a id="task-config-py" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>task_config.py</h3>
<p>åœ¨è¯¥æ–‡ä»¶ä¸­æˆ‘ä»¬è¦æ·»åŠ  <strong>code</strong> ä»»åŠ¡é…ç½®ï¼Œæ·»åŠ å¦‚ä¸‹ï¼š</p>
<blockquote>
<p>æ³¨ï¼šç”±äºæˆ‘ä»¬é‡‡ç”¨é¢å¤–çš„æ–¹å¼è¿›è¡ŒéªŒè¯æŒ‡æ ‡ï¼Œå› æ­¤ä¸ä¼šæœ‰ <code>generation_args</code> å‚æ•°ã€‚</p>
</blockquote>
<pre><code class="language-python">&quot;code&quot;: {&quot;train_datasets&quot;: [&quot;code_122k&quot;],
    &quot;eval_datasets&quot;: None,
    &quot;task_prompt_template&quot;: alpaca_prompt_template,
    &quot;trigger_tokens&quot;: &quot;### Response:&quot;
},
</code></pre>
<h3><a id="train-py" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>train.py</h3>
<ul>
<li>å°† code task åŠ å…¥åˆ° assert ä¸­ï¼š</li>
</ul>
<pre><code class="language-python">    assert task in {
        &quot;commonsense&quot;, &quot;math&quot;, &quot;alpaca&quot;, &quot;instruct&quot;, &quot;ultrafeedback&quot;, &quot;glue&quot;, &quot;gsm8k&quot;,
        &quot;ultrafeedback_pair&quot;, &quot;code&quot;
    }
</code></pre>
<ul>
<li>åœ¨æ‰€æœ‰ eval çš„éƒ¨åˆ†ï¼Œå¯¹ <code>task == code</code> åšä»¥åŒºåˆ†ï¼šè‹¥æ˜¯ code ä»»åŠ¡åˆ™ä¸è¿›è¡Œ eval ç¯èŠ‚ï¼š</li>
</ul>
<pre><code class="language-python"># 1
if task != &quot;code&quot;:
    if task == &quot;glue&quot;:
        eval_datasets = [train_dataset]
    else:
        eval_datasets = task_config[task][&quot;eval_datasets&quot;] if eval_dataset is None else [eval_dataset]

# 2
if task != &quot;code&quot;:
    # äº§ç”Ÿæµ‹è¯•æ•°æ®é›†
    all_eval_datasets = {}
    for eval_dataset in eval_datasets:
        test_splits = test_split.split(&quot;;&quot;)
        all_eval_datasets[eval_dataset] = {}
        for split in test_splits:
            raw_eval = ReftDataset(task, eval_dataset if task == &quot;glue&quot; else os.path.join(data_dir, eval_dataset), 
                tokenizer, data_split=split, seed=seed, max_n_example=max_n_eval_example,
                **{&quot;num_interventions&quot;: len(layers), &quot;position&quot;: position, 
                &quot;share_weights&quot;: share_weights}
            )all_eval_datasets[eval_dataset][split] = [raw_eval, raw_eval.raw_dataset]
    eval_datasets = all_eval_datasets

# 3
if task != &quot;code&quot;:
    # ensure everything is in eval mode
    reft_model.model.eval()for k,v in reft_model.interventions.items():
        _ = v[0].eval()print({&quot;n_params&quot;: n_params})
    # do eval
    eval_results = {}
    for dataset_name in eval_datasets:
        # split evalset into chunks
        for split, (eval_dataset, data_items) in eval_datasets[dataset_name].items():
            
            generations, stats = compute_metrics(
                task, dataset_name, reft_model, tokenizer, eval_dataset, data_items,
                trigger_tokens, run_name, eval_batch_size, 
                data_collator if task in classification_tasks else None,
                split, greedy_decoding, temperature, top_p, top_k
            )
            
            # log
            eval_results.update(stats)
            if is_wandb:
                wandb.log(stats)
            generations = stats if generations is None else generations
            result_json_file_name = f&quot;{output_dir}/{run_name}/{dataset_name}_{split}_outputs.json&quot;
            with open(result_json_file_name, 'w') as json_file:
                json.dump(generations, json_file, indent=4)

    # log final eval stats
    result_json_file_name = f&quot;{output_dir}/{run_name}/eval_results.json&quot;
    eval_results[&quot;n_params&quot;] = n_params
    with open(result_json_file_name, 'w') as json_file:
        json.dump(eval_results, json_file, indent=4)

    print(f&quot;Training results can be found in {output_dir}/{run_name}&quot;)
</code></pre>
<h3><a id="dataset-py-in-loreft" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>dataset.py(in loreft)</h3>
<ul>
<li>ç”±äºæˆ‘ä»¬å·²ç»å°†æ•°æ®é›†æ”¹æˆå’Œ commonsense ç›¸åŒç±»å‹çš„è®­ç»ƒæ•°æ®é›†åç§°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦åœ¨<br />
ç±» <code>LoReftSupervisedDataset(ReftDataset)</code> ä¸­ä¿®æ”¹å…¶ <code>preprocess</code> å‡½æ•°ï¼ŒåŒæ ·æ·»åŠ  code ä»»åŠ¡ï¼š</li>
</ul>
<pre><code class="language-python">elif self.task in [&quot;math&quot;, &quot;commonsense&quot;, &quot;ultrafeedback&quot;, &quot;code&quot;]:
    self.data_path = os.path.join(self.data_path, self.data_split + &quot;.json&quot;)
</code></pre>
<ul>
<li>åŒæ ·çš„ï¼Œåœ¨ç±» <code>LoReftSupervisedDataset(ReftDataset)</code> ä¸­çš„ <code>tokenize</code> å‡½æ•°ä¸­ï¼Œéœ€è¦å°† code ä»»åŠ¡æ·»åŠ åˆ°å…¶ä¸­ï¼š</li>
</ul>
<pre><code class="language-python">elif self.task in [&quot;alpaca&quot;, &quot;instruct&quot;, &quot;ultrafeedback&quot;, &quot;ultrafeedback_pair&quot;, &quot;tatsu-lab/alpaca_eval&quot;, &quot;code&quot;]:
    if 'input' not in data_item or data_item['input'] == &quot;&quot;:
        base_prompt = alpaca_prompt_no_input_template % (data_item['instruction'])
    else:
        base_prompt = self.task_prompt_template % (data_item['instruction'], data_item['input'])
</code></pre>
<h2><a id="train" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train</h2>
<p>åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œæˆ‘ä»¬è¿˜éœ€æ‰‹åŠ¨è°ƒæ•´å…¥å‚ <code>max_length</code>ï¼Œå®ƒå†³å®šæ¨¡å‹è¾“å…¥çš„æœ€å¤§é•¿åº¦ã€‚ä» <a href="https://github.com/bigcode-project/bigcode-evaluation-harness" title="bigcode-evaluation-harness">bigcode-evaluation-harness</a> çš„ <code>finetune</code> æ–‡ä»¶å¤¹å¯ä»¥çœ‹åˆ°ï¼Œåœ¨å¾®è°ƒä¸åŒæ•°æ®é›†çš„æ•°æ®é›†æ—¶ï¼Œé€šå¸¸éƒ½æ˜¯å°† <code>max_length</code> è®¾ç½®ä¸º <strong>1024</strong>ï¼Œå› æ­¤æˆ‘ä»¬ä¹Ÿæ‰‹åŠ¨è®¾ç½®ä¸º 1024ã€‚</p>
<p>åŒæ—¶ç”±äº max_length å¢å¤§ï¼Œç›¸åº”å¯¹æ˜¾å­˜å ç”¨å°±ä¼šå˜é«˜ï¼Œå› æ­¤å°† batch_size è®¾ä¸º 2ï¼Œgradient_accumulation_steps è®¾ä¸º 16ã€‚</p>
<p>åœ¨ç»ˆç«¯è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼Œè¿›è¡Œè®­ç»ƒã€‚</p>
<pre><code class="language-shell"># æ–°å»ºçª—å£
screen -S LoReFT-llama3-8B-Base-Code

# è®­ç»ƒ
python train.py -task code \
-data_dir dataset \
-model Meta-Llama-3-8B \
-seed 42 \
-l all -r 8 -p f7+l7 -e 6 -lr 9e-4 \
-type LoreftIntervention \
-batch_size 2 \
-gradient_accumulation_steps 16 \
-eval_batch_size 2 \
--dropout 0.00 \
--test_split test \
--max_length 1024 \
--use_normalized_template \
--share_weights \
--warmup_ratio 0.1 \
--greedy_decoding \
-is_wandb \
-wandb_name prada-lab \
--wandb_proj just_fot_test \
--save_model    # ç”±äºæˆ‘ä»¬è¦é¢å¤–çš„è¿›è¡Œè¯„æµ‹ï¼Œå› æ­¤éœ€è¦ä¿å­˜æ¨¡å‹
</code></pre>
<p><br />
å¼€å§‹è®­ç»ƒï¼š</p>
<pre><code class="language-shell">task: code, model: Meta-Llama-3-8B, intervention_type: LoreftIntervention, layers: all, rank: 8, position: f7+l7, epoch: 6, train_on_inputs: False, max_length: 1024, allow_cls_grad: False
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
adding a special padding token...
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True, 'test_split': 'test'}
loading data for dataset:  dataset/code_122k/train.json
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121959/121959 [02:17&lt;00:00, 889.70it/s]
config.json: 654B [00:00, 148kB/s]                                                                                                                                                            
config.json: 654B [00:00, 636kB/s]                                                                                                                                                            
model.safetensors.index.json: 23.9kB [00:00, 17.4MB/s]                                                                                                                                        
model-00001-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.98G/4.98G [04:38&lt;00:00, 17.9MB/s]
model-00002-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.00G/5.00G [04:47&lt;00:00, 17.4MB/s]
model-00003-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.92G/4.92G [04:40&lt;00:00, 17.5MB/s]
model-00004-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.17G/1.17G [01:05&lt;00:00, 17.9MB/s]
Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [15:14&lt;00:00, 228.52s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08&lt;00:00,  2.06s/it]
generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:00&lt;00:00, 37.2kB/s]
trainable intervention params: 2,097,408 || trainable model params: 0
model params: 8,030,269,440 || trainable%: 0.0261187749137344
wandb: Currently logged in as: nnyy (prada-lab). Use `wandb login --relogin` to force relogin
wandb: WARNING Path wandb/wandb/ wasn't writable, using system temp directory.
wandb: WARNING Path wandb/wandb/ wasn't writable, using system temp directory
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /tmp/wandb/run-20240508_211702-56sh3v4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Meta-Llama-3-8B.code.20240508205903869903
wandb: â­ï¸ View project at https://wandb.ai/prada-lab/just_fot_test
wandb: ğŸš€ View run at https://wandb.ai/prada-lab/just_fot_test/runs/56sh3v4t
{'loss': 0.7097, 'grad_norm': 2.599954843521118, 'learning_rate': 3.935286401399213e-07, 'epoch': 0.0}                                                                                        
{'loss': 0.6133, 'grad_norm': 2.2335927486419678, 'learning_rate': 7.870572802798426e-07, 'epoch': 0.0}                                                                                       
{'loss': 0.659, 'grad_norm': 2.338649034500122, 'learning_rate': 1.1805859204197638e-06, 'epoch': 0.0}                                                                                        
  0%|                                                                                                                                                    | 3/22866 [00:20&lt;42:47:26,  6.74s/it]
</code></pre>
<p><br />
è®­ç»ƒç»“æŸåï¼Œå¯ä»¥çœ‹åˆ°æ¨¡å‹è¢«ä¿å­˜åˆ°<code>/home/workspace/nanyang/pyreft/examples/loreft/official_results/Meta-Llama-3-8B.code.20240509210531714954</code>ä¸­ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼š<strong>è¯¥æ¨¡å‹å¹¶éå¾®è°ƒåæ‰€æœ‰çš„æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ä¸ªè¾…åŠ©å“ï¼Œéœ€è¦é…åˆåŸæ¨¡å‹ä½¿ç”¨ã€‚</strong> è¯¥æ¨¡å‹æ–‡ä»¶å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<pre><code class="language-plain_text">â”œâ”€â”€ /home/workspace/nanyang/pyreft/examples/loreft/official_results/Meta-Llama-3-8B.code.20240509210531714954
â”‚   â”œâ”€â”€ args.json                                                    # æè¿°äº†å¾®è°ƒä»»åŠ¡
â”‚   â”œâ”€â”€ config.json                                                  # æè¿°äº†interventionç›¸å…³
â”‚   â”œâ”€â”€ intkey_layer.0.comp.block_output.unit.pos.nunit.1#0.bin      # ç¬¬1å±‚ç›¸å…³é…ç½®
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ intkey_layer.31.comp.block_output.unit.pos.nunit.1#0.bin     # ç¬¬32å±‚ç›¸å…³é…ç½®
</code></pre>
<p><br />
è‹¥è¦é‡æ–°åŠ è½½è¯¥æ¨¡å‹ï¼Œåˆ™åº”é‡‡ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š</p>
<pre><code class="language-python">import torch, transformers, pyreft
device = &quot;cuda&quot;

# load base model
model_name_or_path = &quot;your/base/model/path&quot;     # e.g '/root/autodl-tmp/.cache/huggingface/hub/models--Meta-Llama-3-8B/snapshots/1460c22666392e470910ce3d44ffeb2ab7dbd4df'
model = transformers.AutoModelForCausalLM.from_pretrained(
    model_name_or_path, torch_dtype=torch.bfloat16, device_map=device)

# load reft model
reft_model = pyreft.ReftModel.load(
    &quot;your/reft/model/path&quot;,                     # e.g '/root/autodl-tmp/pyreft/examples/loreft/official_results/Meta-Llama-3-8B.code.20240509210531714954'
    model   
)
</code></pre>
<p><br />
æ³¨æ„ï¼šåŠ è½½åçš„æ¨¡å‹ï¼Œåœ¨generateæ—¶ï¼Œå¹¶éè°ƒç”¨çš„<code>transformers</code>åº“ä¸­çš„<code>generate</code>å‡½æ•°ï¼Œè€Œæ˜¯<code>pyvene.IntervenableModel</code>ç±»ä¸­å®šä¹‰çš„<code>generate</code>å‡½æ•°ã€‚</p>
<h2><a id="result" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Result</h2>
<h3><a id="train" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train</h3>
<p>è¯¥éƒ¨åˆ†è®°å½• llama3-8b-base åœ¨å¾®è°ƒcode taskæ—¶çš„è®­ç»ƒå‚æ•°æƒ…å†µã€‚</p>
<p><img src="media/17150707056943/epoch.png" alt="epoch" /></p>
<p><img src="media/17150707056943/global_step.png" alt="global_step" /></p>
<p><img src="media/17150707056943/grad_norm.png" alt="grad_norm" /></p>
<p><img src="media/17150707056943/learning_rate.png" alt="learning_rate" /></p>
<p><img src="media/17150707056943/loss.png" alt="loss" /></p>
<p><img src="media/17150707056943/n_params.png" alt="n_params" /></p>
<h3><a id="system" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>System</h3>
<p>è¯¥éƒ¨åˆ†è®°å½• llama3-8b-base åœ¨å¾®è°ƒcode taskæ—¶çš„ç³»ç»Ÿæƒ…å†µã€‚</p>
<p><img src="media/17150707056943/Disk%20I_O%20Utilization%20-MB-.png" alt="Disk I_O Utilization -MB-" /></p>
<p><img src="media/17150707056943/Disk%20Utilization%20-%25-.png" alt="Disk Utilization -%-" /></p>
<p><img src="media/17150707056943/Disk%20Utilization%20-GB-.png" alt="Disk Utilization -GB-" /></p>
<p><img src="media/17150707056943/GPU%20Memory%20Allocated%20-%25-.png" alt="GPU Memory Allocated -%-" /></p>
<p><img src="media/17150707056943/GPU%20Power%20Usage%20-%25-.png" alt="GPU Power Usage -%-" /></p>
<p><img src="media/17150707056943/GPU%20Power%20Usage%20-W-.png" alt="GPU Power Usage -W-" /></p>
<p><img src="media/17150707056943/GPU%20Temp%20-%E2%84%83-.png" alt="GPU Temp -â„ƒ-" /></p>
<p><img src="media/17150707056943/GPU%20Time%20Spent%20Accessing%20Memory%20-%25-.png" alt="GPU Time Spent Accessing Memory -%-" /></p>
<p><img src="media/17150707056943/GPU%20Utilization%20-%25-.png" alt="GPU Utilization -%-" /></p>
<p><img src="media/17150707056943/gpu.0.memoryAllocatedBytes.png" alt="gpu.0.memoryAllocatedBytes" /></p>
<p><img src="media/17150707056943/Network%20Traffic%20-bytes-.png" alt="Network Traffic -bytes-" /></p>
<p><img src="media/17150707056943/Process%20CPU%20Threads%20In%20Use.png" alt="Process CPU Threads In Use" /></p>
<p><img src="media/17150707056943/Process%20CPU%20Utilization%20-%25-.png" alt="Process CPU Utilization -%-" /></p>
<p><img src="media/17150707056943/Process%20Memory%20Available%20-non-swap-%20-MB-.png" alt="Process Memory Available -non-swap- -MB-" /></p>
<p><img src="media/17150707056943/Process%20Memory%20In%20Use%20-non-swap-%20-%25-.png" alt="Process Memory In Use -non-swap- -%-" /></p>
<p><img src="media/17150707056943/Process%20Memory%20In%20Use%20-non-swap-%20-MB-.png" alt="Process Memory In Use -non-swap- -MB-" /></p>
<p><img src="media/17150707056943/System%20CPU%20Utilization%20-per%20core-%20-%25-.png" alt="System CPU Utilization -per core- -%-" /></p>
<p><img src="media/17150707056943/System%20Memory%20Utilization%20-%25-.png" alt="System Memory Utilization -%-" /></p>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script>!function(){if("undefined"!=typeof Prism&&"undefined"!=typeof document){var e=[],t={},n=function(){};Prism.plugins.toolbar={};var a=Prism.plugins.toolbar.registerButton=function(n,a){var r;r="function"==typeof a?a:function(e){var t;return"function"==typeof a.onClick?((t=document.createElement("button")).type="button",t.addEventListener("click",(function(){a.onClick.call(this,e)}))):"string"==typeof a.url?(t=document.createElement("a")).href=a.url:t=document.createElement("span"),a.className&&t.classList.add(a.className),t.textContent=a.text,t},n in t?console.warn('There is a button with the key "'+n+'" registered already.'):e.push(t[n]=r)},r=Prism.plugins.toolbar.hook=function(a){var r=a.element.parentNode;var l=a.element.classList;if(l.contains('language-mermaid') || l.contains('language-echarts') || l.contains('language-plantuml')){return;} if(r&&/pre/i.test(r.nodeName)&&!r.parentNode.classList.contains("code-toolbar")){var o=document.createElement("div");o.classList.add("code-toolbar"),r.parentNode.insertBefore(o,r),o.appendChild(r);var i=document.createElement("div");i.classList.add("toolbar");var l=e,d=function(e){for(;e;){var t=e.getAttribute("data-toolbar-order");if(null!=t)return(t=t.trim()).length?t.split(/\s*,\s*/g):[];e=e.parentElement}}(a.element);d&&(l=d.map((function(e){return t[e]||n}))),l.forEach((function(e){var t=e(a);if(t){var n=document.createElement("div");n.classList.add("toolbar-item"),n.appendChild(t),i.appendChild(n)}})),o.appendChild(i)}};a("label",(function(e){var t=e.element.parentNode;if(t&&/pre/i.test(t.nodeName)&&t.hasAttribute("data-label")){var n,a,r=t.getAttribute("data-label");try{a=document.querySelector("template#"+r)}catch(e){}return a?n=a.content:(t.hasAttribute("data-url")?(n=document.createElement("a")).href=t.getAttribute("data-url"):n=document.createElement("span"),n.textContent=r),n}})),Prism.hooks.add("complete",r)}}();</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.css"><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script><style>div.code-toolbar > .toolbar > .toolbar-item > a, div.code-toolbar > .toolbar > .toolbar-item > button, div.code-toolbar > .toolbar > .toolbar-item > span {padding: 4px .5em; background: #f5f2f0; background: rgba(224, 224, 224, 0.4);}</style>


  
    




  </body>
</html>
