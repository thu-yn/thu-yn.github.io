<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    Pointcloud in Transfromer: A Survey - Prepare for the FUTURE
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Prepare for the FUTURE" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            Pointcloud in Transfromer: A Survey   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/04/01</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_Pointcloud%20in%20Transformer.html'>#Pointcloud in Transformer</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <h2><a id="1-introduction" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Introduction</h2>
<h3><a id="1-1-transformer%E7%BB%93%E6%9E%84" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.1 Transformer结构</h3>
<p>对于<a href="https://zhuanlan.zhihu.com/p/338817680" title="Transformer Interpretation">Transformer</a>在三维点云分析中，传统Transformer的结构如下：</p>
<div style="text-align: center">
<img src="media/17119019748705/1-1.png"/>
<p>图1 传统Transformer结构图</p>
</div>
<p>由于点云分割等稠密预测任务的需要，涉及点云处理的Transformer网络结构的Decoder部分往往会重新设计。学者通常采用<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">PointNet++</a>或包含了Transformer块的卷积神经网络作为处理点云数据的方法。</p>
<h3><a id="1-2-encoder%E7%AB%AF%E5%A4%84%E7%90%86%E8%8C%83%E5%BC%8F" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2 Encoder端处理范式</h3>
<p>通常的处理范式。对于一个输入点云\(P=\{p_1,\ p_2,\ p_3,\ \ldots,p_N\}\in R^{N\times D}\)，其中\(D\)是输入点云的特征维度。则在Encoder模块中将有以下操作：</p>
<ol>
<li>
<p><strong><a href="https://zhuanlan.zhihu.com/p/372279569" title="Embedding">构造词向量</a></strong>。点云\(P\)将被投影到高维特征空间，生成词特征矩阵\(X \in R^{N\times C}\)。此操作可以通过多层感知机MLP或特征提取骨干网络（如<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8099499" title="PointNet">PointNet</a>）来实现。</p>
</li>
<li>
<p><strong><a href="https://zhuanlan.zhihu.com/p/372279569" title="Embedding">位置编码</a></strong>。用于捕捉几何信息或输入点的相对顺序，生成位置特征矩阵\(B \in R^{N\times C}\)。此操作可以通过固定编码（如<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="Transformer">Transformer</a>）或可学习编码（如<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf" title="Point-Transformer">Point-Transformer</a>）来实现。</p>
</li>
<li>
<p><strong><a href="https://zhuanlan.zhihu.com/p/609523552" title="Attention">注意力机制</a></strong>。以采用与Transformer中相同的\(sin/cos\)位置编码方式为例，将其位置特征矩阵\(B\)加到词特征矩阵\(X\)中：\(X=X+B \in R^{N\times C}\)，并使用三个可学习权重矩阵\(W_Q \in R^{C\times C_Q}, W_K \in R^{C\times C_K}, W_V \in R^{C\times C}\)将该特征矩阵\(X\)投影到三个不同的特征空间，注意通常\(C_Q=C_K\)。此时\(Query,Key,Value\)矩阵可以表达成如下形式：</p>
<p>\(\begin{align}  \left\{\begin{matrix}    Query=XW_Q \in R^{N\times C_Q} \\Key=XW_K \in R^{N\times C_K} \\Value=XW_V \in R^{N\times C} \end{matrix}\right.  \end{align}\)</p>
<p>在给定\(Query,Key,Value\)矩阵后，自注意力矩阵\(F \in R^{N\times C}\)可以表示为：</p>
<p>\( \begin{align}  F=\operatorname{Attention}(Q, K, V)=\operatorname{Softmax}\left(\frac{Q K^{T}}{\sqrt{C_{K}}}\right) V  \end{align}\)</p>
<p>\(F\)矩阵中每一个特征向量是通过计算所有输入特征的加权和获得的，因此，它能够与所有输入特征建立连接。</p>
</li>
<li>
<p><strong><a href="https://blog.csdn.net/Little_White_9/article/details/123345062" title="Batch&amp;Layer Norm">归一化层</a></strong>。通过在前馈层之前和之后放置归一化层，对特征图进行标准化和归一化。归一化方法可以大体上分为<a href="https://blog.csdn.net/Little_White_9/article/details/123345062" title="Batch&amp;Layer Norm">BatchNorm</a>和<a href="https://blog.csdn.net/Little_White_9/article/details/123345062" title="Batch&amp;Layer Norm">LayerNorm</a>，前者常用于NLP，后者常用于CV领域。</p>
</li>
<li>
<p><strong><a href="https://cleverbobo.github.io/2020/08/30/bp/" title="Feed Forward">前馈层</a></strong>。该层用来增强注意力特征的表示，通常由两层MLP和相应的激活函数构成。</p>
</li>
<li>
<p><strong><a href="https://blog.csdn.net/weixin_51756104/article/details/127232344" title="Residual Connection">残差连接</a></strong>。通过将某一模块的输入与输出相加，可以保证数据经过该模块后的效果不会变的比之前差，并且可以解决梯度消失问题。</p>
</li>
</ol>
<blockquote>
<p>需要注意的是，并非所有处理3D点云的网络都由以上6个组件构成。有一些早期的3D Transformer网络中并没有位置编码模块，它们更关注于自注意力机制在点云上的应用（如<a href="https://www.sciencedirect.com/science/article/pii/S0031320320302491" title="Point Attention">Point Attention</a>或者<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8578582" title="Attentional ShapeContextNet">Attentional ShapeContextNet</a>）；还有一些Transformer网络将位置编码直接合并到词向量模块中（如<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">Point Cloud Transformer</a>采用基于<a href="https://arxiv.org/pdf/1801.07829.pdf" title="EdgeConv">EdgeConv</a>的方法实现）。</p>
</blockquote>
<h3><a id="1-3-transformer%E5%9C%A8%E7%82%B9%E4%BA%91%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3 Transformer在点云中的应用</h3>
<p>主要分为三大种类：</p>
<ol>
<li>基于<strong>实现方式</strong>的分类方法；</li>
<li>基于<strong>数据表示</strong>的分类方法；</li>
<li>基于<strong>任务特征</strong>的实现方法。</li>
</ol>
<div style="text-align: center">
<img src="media/17119019748705/10-1.png"/>
<p>图2 Transformer分类</p>
</div>
<h2><a id="2-transformer-implementation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Transformer Implementation</h2>
<p>细分Point Transformer的实现形式，可以将其主要分为两部分，分别是<strong>操作规模</strong>和<strong>操作空间</strong>。操作规模代表了算法作用点云的范围，主要分为<strong>全局Transformer</strong>和<strong>局部Transformer</strong>；操作空间代表了算法运行的维度，主要分为基于<strong>Point-wise</strong>的Transformer和基于<strong>Channels-wise</strong>的Transformer。</p>
<h3><a id="2-1-operating-scale" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1 Operating Scale</h3>
<p>在以操作规模分类的Transformer网络中，全局Transformer是将Transformer块应用于所有输入点云，以便进行全局点云特征提取；而局部Transformer是将Transformer块应用于局部patch，用来进行局部特征提取。</p>
<h4><a id="2-1-1-global-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1.1 Global Transformer</h4>
<p>对于全局Transformer，其注意力输出\(F\)的每个特征都可以和任一个输入特征\(X\)相连接，并且他与输入的排列具有相同的变化特性，能够学习全局点云的上下文特征。</p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8099499" title="PointNet">PointNet</a>是首个采用全局Transformer结构的<strong>单一尺度</strong>方法，此后<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">Point Cloud Transformer</a>首先提出了一种<strong>邻域嵌入</strong>架构，它将点云的三维坐标作为输入\(P\)，通过该框架将\(P\)映射到高维特征空间，同时还可以将局部信息整合到嵌入特征中，接着这些特征被输入到4个堆叠的全局Encoder块中用来学习语义信息，最终通过全局最大池和平均池提取全局特征用来进行分类和分割。</p>
<div style="text-align: center">
<img src="media/17119019748705/11.png"/>
<p>图3 PointNet Pipeline</p>
</div>
<p>除此之外，<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">Point Cloud Transformer</a>还将注意力模块进行改进，其受到<a href="https://arxiv.org/pdf/1312.6203.pdf" title="Graph convolution networks">Graph convolution networks</a>中拉普拉斯矩阵的启发，构建了名为<strong>Offset</strong>的注意力模块，该注意力模块可以增到注意力权重并减少噪声的影响。</p>
<div style="text-align: center">
<img src="media/17119019748705/12.png"/>
<p>图4 Point CLoud Transformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2104.13053.pdf" title="3DCROSSNet">3CROSSNet</a>是一种<strong>全局跨级跨尺度交叉注意力</strong>的Transformer网络结构。该方法首先对原始输入点云进行<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">FPS</a>（最远点采样），获得三个不同分辨率的点子集。其次利用堆叠的多个共享MLP模块提取每个采样点的局部特征。接着将Encoder块用于每个点子集得到其全局特征提取。最后，该方法提出了跨级交叉注意力模块CLCA和交叉尺度交叉注意力模块CSCA，用于在不同分辨率点子集和不同级别特征之间建立连接，以进行长距离层间和层内依赖关系的建模。</p>
<div style="text-align: center">
<img src="media/17119019748705/13.png"/>
<p>图5 3CORSSNet Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2111.14819.pdf" title="Point-BERT">Point-BERT</a>将<a href="https://arxiv.org/pdf/1810.04805.pdf" title="BERT">BERT</a>用于3D点云处理，提出了一种针对全局3D Transformer的<strong>BERT预训练</strong>策略，用局部patch作为输入，首先利用<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8099499" title="PointNet">mini-PointNet</a>，遵循<a href="https://arxiv.org/pdf/2010.11929.pdf" title="ViT">ViT</a>对输入点云进行Input Embedding，其次使用带有<a href="https://arxiv.org/pdf/1609.02200.pdf" title="dVAE">dVAE</a>（离散变分自动编码器）的点云<a href="https://cloud.tencent.com/developer/article/2317900?areaId=106001" title="Tokenizer">Tokenizer</a>，将Embedding后的点云转换成离散的point token用于预训练。其中Tokenizer网络由<a href="https://arxiv.org/pdf/1801.07829.pdf" title="DGCNN">DGCNN</a>改编，用于产生有意义的局部信息聚合，并通过基于dVAE的点云重建来进行学习。在预训练期间，一些带有MASK的token被输入进Encoder网络，在Tokenizer生成的point token监督下，可以训练Encoder恢复被MASK位置的相应token。</p>
<div style="text-align: center">
<img src="media/17119019748705/14.png"/>
<p>图6 Point-BERT Pipeline</p>
</div>
<h4><a id="2-1-2-local-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1.2 Local Transformer</h4>
<p>与全局Transformer相比，局部Transformer更关注局部patch而非全局点云上的特征聚合。</p>
<p><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf" title="Point-Transformer">Point Transformer</a>采用<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">PointNet++</a>分层架构进行点云分类和分割。他更关注局部patch处理，采用局部Transformer块代替PointNet++中的共享MLP块。并且PT使用的自注意力算子是<a href="https://arxiv.org/pdf/2004.13621.pdf" title="vector attention">vector attention</a>而非scalar attention，<strong>vector attention</strong>的优点是其支持以通道的方式而非对整个特征向量分配注意力权重。</p>
<div style="text-align: center">
<img src="media/17119019748705/15.png"/>
<p>图7 Point Transformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2012.11409.pdf" title="Pointformer">Pointformer</a>将Transformer块提取的局部和全局特征结合起来进行3D对象检测。它主要由局部Transformer(LT)块、全局Transformer(GT)块和局部-全局Transformer(LGT)块三种模块构成。其中LT块在<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">FPS</a>生成的每个质心点邻域中应用稠密自注意力操作；GT块以整个点云作为输入，通过自注意力机制学习全局上下文感知特征；<strong>LGT</strong>块采用多尺度交叉注意力模块，将LT的输出作为query，将GT的输出作为key和value进行注意力操作，在LT的局部特征和GT的全局特征之间产生联系。所有质心点都可以用来整合全局信息，从而实现有效的全局特征学习。</p>
<div style="text-align: center">
<img src="media/17119019748705/16.png"/>
<p>图8 Pointformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2203.14508.pdf" title="Stratified Transformer">Stratified Transformer</a>通过3D体素化将点云分割成一组不重叠的立方体窗口，并在每个窗口中执行局部Transformer操作。Stratified Transformer是一种Encoder-Decoder架构。其中Encoder是由多个阶段组成的分层结构，每个阶段都具有两个连续的Transformer块，前一个块通过<strong>SSA</strong>（分层自注意力）来捕获长程和短程依赖性，后一个块通过<strong>Shifted SSA</strong>（带滑窗的分层自注意力）来进一步加强不同独立窗口之间的联系。Decoder中，Encoder特征类似于U-Net的方式逐层上采样变得更密集。</p>
<div style="text-align: center">
<img src="media/17119019748705/17.png"/>
<p>图9 Stratified Transformer Pipeline</p>
</div>
<p>为了解决局部Transformer捕获全局信息较弱的问题，SSA为每个query point生成密集的局部key point和稀疏的远程key point。其中前者在key point所属的窗口中生成，后者是通过对整个输入点云进行下采样后，在更大的窗口中生成的。此时query point的感受野就不再局限于局部窗口，使SSA可以捕获全局信息。另外要注意的是，Stratified Transformer在初始的Point Embedding阶段执行了<a href="https://arxiv.org/pdf/1904.08889.pdf" title="KPConv">KPConv</a>嵌入，以便能更好的提取输入点云的局部几何信息。</p>
<h3><a id="2-2-operating-space" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2 Operating Space</h3>
<p>在以操作规模分类的Transformer网络中，Point-wise Transformer注重不同<strong>point</strong>之间的相似性；而Channel-wise Transformer沿<strong>channel</strong>分配权重。其Query与Key之间的similarity可以分别表示为如下形式：</p>
<p>\( \begin{align}  \operatorname{Point-wise Simi}(Q, K)=\operatorname{Softmax}\left(\frac{Q K^{T}}{\sqrt{C_{K}}}\right)   \end{align}\)</p>
<p>\( \begin{align}  \operatorname{Channel-wise Simi}(Q, K)=\operatorname{Softmax}\left(\frac{Q ^{T} K}{\sqrt{C_{K}}}\right)   \end{align}\)</p>
<p>其中\(Point-wise \; Simi\in R^{N\times N}, Channel-wise \; Simi\in R^{C_{K}\times C_{K}}\)</p>
<h4><a id="2-2-1-point-wise-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.1 Point-wise Transformer</h4>
<p>Point-wise Transformer旨在研究点之间的空间相似性，其输出特征是所有输入特征的加权和。由于2.1节中所有的全局或局部Transformer都是直接对点进行操作和分类的，所以其均可以视为Point-wise Transformer。</p>
<p><a href="https://arxiv.org/pdf/2112.04863.pdf" title="3D Medical Point Transformer">3D Medical Point Transformer</a>是一种用于医学点云分析的Transformer架构。它包括一个用于分类的分层point-wise transformer和一个用于分割的统一尺度point-wise transformer，每个Transformer块都集成了卷积运算，并在该块之前添加了使用<a href="https://arxiv.org/pdf/1801.07829.pdf" title="DGCNN">DGCNN</a>实现的局部特征提取模块。为了针对医学领域训练样本不足的问题，3DMedPT提出了一个<strong>MGR</strong>（多图推理）的模块用来丰富特征表示。</p>
<div style="text-align: center">
<img src="media/17119019748705/18.png"/>
<p>图10 3D Medical Point Transformer Pipeline</p>
</div>
<h4><a id="2-2-2-channel-wise-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.2 Channel-wise Transformer</h4>
<p>Channel-wise Transformer专注于研究不同特征通道之间的相似性从而改进上下文信息建模。</p>
<p><a href="https://arxiv.org/pdf/1911.12885.pdf" title="CAA">GBNPCC</a>利用纠错反馈结构的思想，提出了一种用于局部特征捕获的反投影模块。它设计了一个<strong>通道式亲和力注意力（CAA）模块</strong>，以实现更好的特征表示。具体来说，CAA 模块由两个模块组成：紧凑通道比较器 (CCC) 模块和通道亲和性估计器 (CAE) 模块。 CCC模块可以生成通道空间中的相似度矩阵。 CAE模块进一步计算了一个亲和力矩阵，其中具有较高注意力值的元素代表相应两个通道的较低相似度。 此操作可以锐化注意力权重并避免聚集相似/冗余信息。 因此，输出特征的每个通道都与其他不同的通道有足够的交互。</p>
<div style="text-align: center">
<img src="media/17119019748705/19.png"/>
<p>图11 GBNPCC Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2112.02507.pdf" title="TransformerConv">TransformerConv</a>采用<strong>将特征通道与坐标通道结合</strong>起来构造Transformer。其Query矩阵是由坐标信息不经任何线性变换直接生成的，而Key矩阵是由通过MLP的特征通道生成的。其相似性矩阵\(Similarity(Q,K)\)采用元素乘法而非点积生成，此时相似性矩阵可以表示每个点的坐标通道和特征通道之间的关系。之后通过MLP将Key矩阵投影到潜在空间以构造Value矩阵，并将相似性矩阵和Value矩阵相乘以获得注意力矩阵\(Attention(Q,K,V)\)，通过对其进行通道最大池操作来生成输出特征。</p>
<div style="text-align: center">
<img src="media/17119019748705/20.png"/>
<p>图12 TransformerConv Pipeline</p>
</div>
<h3><a id="2-3-efficient-transformers" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.3 Efficient Transformers</h3>
<p>对于标准的Transformer过程，若输入点云的数量为\(N\)，其核心——自注意力模块的计算和存储复杂度均为\(O(N^2)\)，这也成为在大规模点云数据集上应用Transformer的主要缺点。因此，通过改进自注意力模块以提高计算效率的Transformer研究也逐渐受到科研人员的关注。</p>
<p><a href="https://arxiv.org/pdf/2102.08606.pdf" title="Centroid Transformers">Centroid Transformers</a>将\(N\)个点特征作为输入，其输出只有\(M\)个特征\((M \leq N)\)。其核心思想是<strong>输入点云中的关键信息可以通过较少数量的输出（亦称为质心）来概括</strong>。首先通过优化一个通用的\(soft \; K-means\)目标函数，从\(N\)个输入构建\(M\)个质心，由质心信息构建Query矩阵，输入信息构建Key矩阵，使计算的时间复杂度由\(O(N^2)\)缩减为\(O(NM)\)。为了进一步降低时间复杂度，该方法还采用了KNN近似，本质上是将全局Transformer转换为局部Transformer，此时相似性矩阵是通过衡量每个query特征向量与其K个邻近的key向量之间的关系而生成，将时间复杂度进一步降低到\(O(NK)\)。</p>
<div style="text-align: center">
<img src="media/17119019748705/21.png"/>
<p>图13 Centroid Transformers Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2202.06263.pdf" title="LighTN">LighTN</a>旨在简化标准Transformer的主要部件，在提高效率的同时保持其卓越性能。其首先删除了Position Embedding模块（<strong>由于输入的3D坐标已经包含位置信息，可以被视为位置编码的替代</strong>），其行为移除了位置编码的计算开销。其次，它利用小尺寸共享线性层作为Input Embedding Layer，与<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">PCT</a>中的相比Embedding特征维度降低了一半，可以减少Input Embedding的计算成本。最后，该方法提出了一个单头自相关层作为自注意力模块，抛弃了投影矩阵\(W_Q , W_K, W_V\)，减少了可学习参数以实现高效，其自相关模块可以表示为：</p>
<p>\( \begin{align}  SA(X)=FC_{out}(C(X)) \end{align}\)</p>
<p>\( \begin{align}  C(X)=\operatorname{Softmax}\left(\frac{X X^{T}}{\sqrt{C}}\right)X \end{align}\)</p>
<p>这里\(SA(*)\)表示自注意力块，\(FC_{out}\)表示线性变换，\(\operatorname{Softmax}\)表示激活函数，\(C\)是输入特征维度。最后，该方法在FFN中构建了三个线性层，并在中间层采用了<a href="https://arxiv.org/pdf/2008.00623.pdf" title="expand reduce">expand reduce</a>策略，可以减轻因自注意力模块中可学习参数的减少造成的负面影响。</p>
<div style="text-align: center">
<img src="media/17119019748705/22.png"/>
<p>图14 LighTN Pipeline</p>
</div>
<h2><a id="3-data-representation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Data Representation</h2>
<p>3D数据有多种表示形式，主要分为<strong>点</strong>表示和<strong>体素</strong>表示。这两种形式均可用作3D Transformer的输入，并且之间还可以互相转换。因此根据输入格式的不同，可以将3D Transformer分为Voxel-based Transformer和Point-based Transformer。</p>
<h3><a id="3-1-voxel-based-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 Voxel-based Transformer</h3>
<p>由于3D点云通常是非结构化的，因此无法通过传统的卷积算子进行处理，除非将其转化为体素形式后，其结构与图像才可以相似。最通用的3D点云体素化方法流程为：通过光栅化将点云的边界框有规律的划分为3D长方体保留包含点云的体素，并生成点云的体素表示。</p>
<p>受到稀疏卷积在体素数据上运行的效率的启发，<a href="https://arxiv.org/pdf/2109.02497.pdf" title="VoTr">VoTr</a>主干用于对3D点云实施体素变换，以满足3D对象检测任务。其方法提出了Submanifold Voxel模块和Sparse Voxel模块，<strong>分别从非空和空体素中提取点云特征</strong>。在这两个模块中，基于多头自注意力机制实现了局部注意力和扩张注意力操作，实现了大量体素下的低计算消耗。</p>
<div style="text-align: center">
<img src="media/17119019748705/23.png"/>
<p>图15 VoTr Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2203.10314.pdf" title="VoxSeT">VoxSeT</a>致力于解决Transformer基于体素的室外3D检测的计算问题，其以 <strong>Set-to-Set</strong>的形式检测户外物体。该方法建立在基于体素的集合注意力（VSA）模块上，通过两个交叉注意力减少每个体素中的自注意力，并对一组潜在代码引起的隐藏空间中的特征进行建模。VSA模块可以使VoxSeT管理大范围内任意大小的体素化点簇，并以线性复杂度的方式进行处理。</p>
<div style="text-align: center">
<img src="media/17119019748705/24.png"/>
<p>图16 VoxSeT Pipeline</p>
</div>
<p>收到大规模点云上基于体素表示的有效性的启发，基于体素的Transformer也可以应用于大规模点云的处理。<a href="https://arxiv.org/pdf/2105.00149.pdf" title="SVT-Net">SVT-Net</a>提出了用于<strong>大规模地点识别的超轻量级稀疏体素Transformer</strong>。该框架采用了基于原子的稀疏体素Transformer（ASVT）和基于集群的稀疏体素Transformer（CSVT），其中前者用于编码短程局部关系，后者用于学习远程上下文关系。</p>
<div style="text-align: center">
<img src="media/17119019748705/25.png"/>
<p>图17 SVT-Net Pipeline</p>
</div>
<p><a href="https://openreview.net/pdf?id=3SUToIxuIT3" title="EPT">EPT</a>提出的高效点Transformer用于从点云理解大规模3D场景。为了<strong>解决点云体素化过程中几何信息丢失</strong>的问题，其引入了中心感知体素化和去体素化操作。并在此基础上，采用高效自注意力（ESA）层来提取体素特征。</p>
<div style="text-align: center">
<img src="media/17119019748705/26.png"/>
<p>图18 EPT Pipeline</p>
</div>
<h3><a id="3-2-point-based-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 Point-based Transformer</h3>
<p>具有规定格式的体素在点云表达上势必会造成一定的几何信息丢失，因此大多数基于Transformer的点云处理框架都属于基于点的Transformer。其架构通常分为<strong>均匀尺度架构</strong>和<strong>多尺度架构</strong>。</p>
<h4><a id="3-2-1-uniform-scale" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.1 Uniform Scale</h4>
<p>均匀尺度架构通常在数据处理过程中保持点特征的尺度恒定，每个模块的输出特征数量和输入特征数量一致。<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">PCT</a>是最具代表性的工作之一。在Input Embedding后，PCT的四个全局Transformer块直接对叠在一起细化点特征，这有利于全局特征的学习，并且缺乏分层特征聚合的操作也有利于点云分割等稠密预测任务的Decoder设计。然而该方案也会导致在提取局部特征方面较弱，并且会导致较高的计算占用量和内存消耗。</p>
<div style="text-align: center">
<img src="media/17119019748705/12.png"/>
<p>图19 Point CLoud Transformer Pipeline</p>
</div>
<h4><a id="3-2-2-multi-scale" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2.2 Multi Scale</h4>
<p>多尺度Transformer是指在特征提取时采用渐进点采样策略的Transformer，也称为分层Transformer。<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf" title="Point-Transformer">PT</a>首次将多尺度结构引入纯Transformer网络，其Transformer层被用于渐进的对子点集进行采样。采样不仅可以通过减少Transformer网络中的参数而加速计算，还可以与基于KNN的局部特征聚合操作相结合，有利于诸如精细语义感知的任务，例如点云分割和点云补全。此外，网络最后一层经过高度聚合的局部特征可以作为全局特征应用于点云分类。</p>
<div style="text-align: center">
<img src="media/17119019748705/15.png"/>
<p>图20 Point Transformer Pipeline</p>
</div>
<p>此外，仍有一些Transformer网络架构通过将卷积算子和Transformer进行结合，达到同时提取局部和全局特征的效果，以实现更好的语义特征表示。</p>
<h2><a id="4-3d-tasks" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. 3D Tasks</h2>
<p>与图像处理相似，3D点云相关任务也可以分为两大类：<strong>高级任务</strong>和<strong>低级任务</strong>。高级任务涉及语义分析，重点是<strong>将3D点云转换为人们可以理解的信息</strong>。低级任务侧重于<strong>探索基本几何信息</strong>，与人类语义理解没有直接关系，但是可以间接辅助高级任务。</p>
<h3><a id="4-1-high-level-task" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1 High-level Task</h3>
<p>高级任务通常包括：点云分类和分割、点云目标检测、点云目标跟踪以及点云配准等等。</p>
<h4><a id="4-1-1-classi%EF%AC%81cation-segmentation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1.1 Classiﬁcation &amp; Segmentation</h4>
<p>3D点云分类旨在将给定的3D形状分类为特定类别，并且用于分割网络的Encoder通常是由分类网络发展而来两者具有很高的相似性。</p>
<p><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Xie_Attentional_ShapeContextNet_for_CVPR_2018_paper.pdf" title="A-SCN">A-SCN</a>首次将自注意力机制引入到点云识别任务中。在受到<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=993558" title="shape context">shape context</a>（形状上下文）的启发后，其首先将输入点云转换为形状上下文表示的形式，该表示由一组同心壳箱构成，随后引入了ShapeContextNet(SCN)来执行点特征的提取。并将点积自注意力模块应用于形状上下文表示中，以便自动捕获丰富的局部和全局信息。</p>
<div style="text-align: center">
<img src="media/17119019748705/27.png"/>
<p>图21 A-SCN Pipeline</p>
</div>
<p><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf" title="Point-Transformer">Point Transformer</a>中，Point Transformer块是在Point Transformer层的基础上以残差方式构建的。其Encoder仅由Point Transformer块、逐点变换和点云分类的池化操作构建。此外PT还使用U-Net结构对点云进行分割，并采用与Encoder对称的Decoder设计。其提出的Transition up模块用于从下采样点集中恢复具有语义特征的原始点云，该模块由线性层、Batch Normalization、ReLU和用于特征映射的三次线性插值模块构成。此外，在Encoder和相应的Decoder之间引入了Skip Connection以促进反向传播。</p>
<div style="text-align: center">
<img src="media/17119019748705/15.png"/>
<p>图22 Point Transformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2111.14819.pdf" title="Point-BERT">Point-BERT</a>通过用于点云分类的Mask Point Modeling任务来预训练纯基于Transformer的模型。点云首先被分为几个局部point batch，然后利用mini PointNet获取每个patch的Embedding Feature，并将一些Feature随机丢弃，其余送到Transformer网络并恢复被mask的token。</p>
<div style="text-align: center">
<img src="media/17119019748705/14.png"/>
<p>图23 Point-BERT Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2108.06076.pdf" title="PVT">Point-Voxel Transformer</a>(PVT)是一种以3D体素为输入的纯粹基于Transformer的点云学习backbone，采用稀疏窗口注意力（SWA）操作在移动窗口配置的非重叠3D体素窗口内执行自注意力，还引入了相对注意力（RA）操作来计算点的细粒度特征。</p>
<div style="text-align: center">
<img src="media/17119019748705/28.png"/>
<p>图24 PVT Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2203.14508.pdf" title="Stratified Transformer">Stratiﬁed Transformer</a>提出了分层Transformer来显式编码全局上下文，其还通过体素化将<a href="https://arxiv.org/pdf/2103.14030.pdf" title="Swin Transformer">Swin Transformer</a>应用于点云处理。分层Transformer将密集的局部点和稀疏的远点均作为key vector,这种操作有利于立方窗口之间的消息传递以及全局信息捕获。</p>
<div style="text-align: center">
<img src="media/17119019748705/17.png"/>
<p>图25 Stratified Transformer Pipeline</p>
</div>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script>window.MathJax = {     tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } ,     startup: {     pageReady() {       return MathJax.startup.defaultPageReady().then(function () {          window.mweb_mathjax_ready_val = 'yes';          if(window.mweb_mathjax_ready !== undefined){ mweb_mathjax_ready(); }       });     }   }};document.addEventListener('DOMContentLoaded', function(event) {    if (typeof Prism != 'undefined') {         Prism.highlightAll();     }});window.mweb_mathjax_ready_val = '';function theMWebMathJaxRenderIsReady(key){ return window.mweb_mathjax_ready_val; }</script><script>window.MathJax = { tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } }; </script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>


  
    




  </body>
</html>
