<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    Pointcloud in Transfromer: A Survey - Pointcloud with Transformer
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Pointcloud with Transformer" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            Pointcloud in Transfromer: A Survey   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/04/01</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <h2><a id="1-introduction" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Introduction</h2>
<h3><a id="1-1-transformer%E7%BB%93%E6%9E%84" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.1 Transformer结构</h3>
<p>对于<a href="https://zhuanlan.zhihu.com/p/338817680" title="Transformer">Transformer</a>在三维点云分析中，传统Transformer的结构如下：</p>
<div style="text-align: center">
<img src="media/17119019748705/1-1.png"/>
<p>图1 传统Transformer结构图</p>
</div>
<p>由于点云分割等稠密预测任务的需要，涉及点云处理的Transformer网络结构的Decoder部分往往会重新设计。学者通常采用<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">PointNet++</a>或包含了Transformer块的卷积神经网络作为处理点云数据的方法。</p>
<h3><a id="1-2-encoder%E7%AB%AF%E5%A4%84%E7%90%86%E8%8C%83%E5%BC%8F" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2 Encoder端处理范式</h3>
<p>通常的处理范式。对于一个输入点云\(P=\{p_1,\ p_2,\ p_3,\ \ldots,p_N\}\in R^{N\times D}\)，其中\(D\)是输入点云的特征维度。则在Encoder模块中将有以下操作：</p>
<ol>
<li>
<p><strong><a href="https://zhuanlan.zhihu.com/p/372279569" title="Embedding">构造词向量</a></strong>。点云\(P\)将被投影到高维特征空间，生成词特征矩阵\(X \in R^{N\times C}\)。此操作可以通过多层感知机MLP或特征提取骨干网络（如<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8099499" title="PointNet">PointNet</a>）来实现。</p>
</li>
<li>
<p><strong><a href="https://zhuanlan.zhihu.com/p/372279569" title="Embedding">位置编码</a></strong>。用于捕捉几何信息或输入点的相对顺序，生成位置特征矩阵\(B \in R^{N\times C}\)。此操作可以通过固定编码（如<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="Transformer">Transformer</a>）或可学习编码（如<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf" title="Point-Transformer">Point-Transformer</a>）来实现。</p>
</li>
<li>
<p><strong><a href="https://zhuanlan.zhihu.com/p/609523552" title="Attention">注意力机制</a></strong>。以采用与Transformer中相同的\(sin/cos\)位置编码方式为例，将其位置特征矩阵\(B\)加到词特征矩阵\(X\)中：\(X=X+B \in R^{N\times C}\)，并使用三个可学习权重矩阵\(W_Q \in R^{C\times C_Q}, W_K \in R^{C\times C_K}, W_V \in R^{C\times C}\)将该特征矩阵\(X\)投影到三个不同的特征空间，注意通常\(C_Q=C_K\)。此时\(Query,Key,Value\)矩阵可以表达成如下形式：</p>
<p>\(\begin{align}  \left\{\begin{matrix}    Query=XW_Q \in R^{N\times C_Q} \\Key=XW_K \in R^{N\times C_K} \\Value=XW_V \in R^{N\times C} \end{matrix}\right.  \end{align}\)</p>
<p>在给定\(Query,Key,Value\)矩阵后，自注意力矩阵\(F \in R^{N\times C}\)可以表示为：</p>
<p>\( \begin{align}  F=\operatorname{Attention}(Q, K, V)=\operatorname{Softmax}\left(\frac{Q K^{T}}{\sqrt{C_{K}}}\right) V  \end{align}\)</p>
<p>\(F\)矩阵中每一个特征向量是通过计算所有输入特征的加权和获得的，因此，它能够与所有输入特征建立连接。</p>
</li>
<li>
<p><strong><a href="https://blog.csdn.net/Little_White_9/article/details/123345062" title="Batch&amp;Layer Norm">归一化层</a></strong>。通过在前馈层之前和之后放置归一化层，对特征图进行标准化和归一化。归一化方法可以大体上分为<a href="https://blog.csdn.net/Little_White_9/article/details/123345062" title="Batch&amp;Layer Norm">BatchNorm</a>和<a href="https://blog.csdn.net/Little_White_9/article/details/123345062" title="Batch&amp;Layer Norm">LayerNorm</a>，前者常用于NLP，后者常用于CV领域。</p>
</li>
<li>
<p><strong><a href="https://cleverbobo.github.io/2020/08/30/bp/" title="Feed Forward">前馈层</a></strong>。该层用来增强注意力特征的表示，通常由两层MLP和相应的激活函数构成。</p>
</li>
<li>
<p><strong><a href="https://blog.csdn.net/weixin_51756104/article/details/127232344" title="Residual Connection">残差连接</a></strong>。通过将某一模块的输入与输出相加，可以保证数据经过该模块后的效果不会变的比之前差，并且可以解决梯度消失问题。</p>
</li>
</ol>
<blockquote>
<p>需要注意的是，并非所有处理3D点云的网络都由以上6个组件构成。有一些早期的3D Transformer网络中并没有位置编码模块，它们更关注于自注意力机制在点云上的应用（如<a href="https://www.sciencedirect.com/science/article/pii/S0031320320302491" title="Point Attention">Point Attention</a>或者<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8578582" title="Attentional ShapeContextNet">Attentional ShapeContextNet</a>）；还有一些Transformer网络将位置编码直接合并到词向量模块中（如<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">Point Cloud Transformer</a>采用基于<a href="https://arxiv.org/pdf/1801.07829.pdf" title="EdgeConv">EdgeConv</a>的方法实现）。</p>
</blockquote>
<h3><a id="1-3-transformer%E5%9C%A8%E7%82%B9%E4%BA%91%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3 Transformer在点云中的应用</h3>
<p>主要分为三大种类：</p>
<ol>
<li>基于<strong>实现方式</strong>的分类方法；</li>
<li>基于<strong>数据表示</strong>的分类方法；</li>
<li>基于<strong>任务特征</strong>的实现方法。</li>
</ol>
<div style="text-align: center">
<img src="media/17119019748705/10-1.png"/>
<p>图2 Transformer分类</p>
</div>
<h2><a id="2-transformer-implementation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Transformer Implementation</h2>
<p>细分Point Transformer的实现形式，可以将其主要分为两部分，分别是<strong>操作规模</strong>和<strong>操作空间</strong>。操作规模代表了算法作用点云的范围，主要分为<strong>全局Transformer</strong>和<strong>局部Transformer</strong>；操作空间代表了算法运行的维度，主要分为基于<strong>Point-wise</strong>的Transformer和基于<strong>Channels-wise</strong>的Transformer。</p>
<h3><a id="2-1-operating-scale" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1 Operating Scale</h3>
<p>在以操作规模分类的Transformer网络中，全局Transformer是将Transformer块应用于所有输入点云，以便进行全局点云特征提取；而局部Transformer是将Transformer块应用于局部patch，用来进行局部特征提取。</p>
<h4><a id="2-1-1-global-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1.1 Global Transformer</h4>
<p>对于全局Transformer，其注意力输出\(F\)的每个特征都可以和任一个输入特征\(X\)相连接，并且他与输入的排列具有相同的变化特性，能够学习全局点云的上下文特征。</p>
<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8099499" title="PointNet">PointNet</a>是首个采用全局Transformer结构的<strong>单一尺度</strong>方法，此后<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">Point Cloud Transformer</a>首先提出了一种<strong>邻域嵌入</strong>架构，它将点云的三维坐标作为输入\(P\)，通过该框架将\(P\)映射到高维特征空间，同时还可以将局部信息整合到嵌入特征中，接着这些特征被输入到4个堆叠的全局Encoder块中用来学习语义信息，最终通过全局最大池和平均池提取全局特征用来进行分类和分割。</p>
<div style="text-align: center">
<img src="media/17119019748705/11.png"/>
<p>图3 PointNet Pipeline</p>
</div>
<p>除此之外，<a href="https://link.springer.com/article/10.1007/s41095-021-0229-5" title="Point Cloud Transformer">Point Cloud Transformer</a>还将注意力模块进行改进，其受到<a href="https://arxiv.org/pdf/1312.6203.pdf" title="Graph convolution networks">Graph convolution networks</a>中拉普拉斯矩阵的启发，构建了名为<strong>Offset</strong>的注意力模块，该注意力模块可以增到注意力权重并减少噪声的影响。</p>
<div style="text-align: center">
<img src="media/17119019748705/12.png"/>
<p>图4 Point CLoud Transformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2104.13053.pdf" title="3DCROSSNet">3CROSSNet</a>是一种<strong>全局跨级跨尺度交叉注意力</strong>的Transformer网络结构。该方法首先对原始输入点云进行<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">FPS</a>（最远点采样），获得三个不同分辨率的点子集。其次利用堆叠的多个共享MLP模块提取每个采样点的局部特征。接着将Encoder块用于每个点子集得到其全局特征提取。最后，该方法提出了跨级交叉注意力模块CLCA和交叉尺度交叉注意力模块CSCA，用于在不同分辨率点子集和不同级别特征之间建立连接，以进行长距离层间和层内依赖关系的建模。</p>
<div style="text-align: center">
<img src="media/17119019748705/13.png"/>
<p>图5 3CORSSNet Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2111.14819.pdf" title="Point-BERT">Point-BERT</a>将<a href="https://arxiv.org/pdf/1810.04805.pdf" title="BERT">BERT</a>用于3D点云处理，提出了一种针对全局3D Transformer的<strong>BERT预训练</strong>策略，用局部patch作为输入，首先利用<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8099499" title="PointNet">mini-PointNet</a>，遵循<a href="https://arxiv.org/pdf/2010.11929.pdf" title="ViT">ViT</a>对输入点云进行Input Embedding，其次使用带有<a href="https://arxiv.org/pdf/1609.02200.pdf" title="dVAE">dVAE</a>（离散变分自动编码器）的点云<a href="https://cloud.tencent.com/developer/article/2317900?areaId=106001" title="Tokenizer">Tokenizer</a>，将Embedding后的点云转换成离散的point token用于预训练。其中Tokenizer网络由<a href="https://arxiv.org/pdf/1801.07829.pdf" title="DGCNN">DGCNN</a>改编，用于产生有意义的局部信息聚合，并通过基于dVAE的点云重建来进行学习。在预训练期间，一些带有MASK的token被输入进Encoder网络，在Tokenizer生成的point token监督下，可以训练Encoder恢复被MASK位置的相应token。</p>
<div style="text-align: center">
<img src="media/17119019748705/14.png"/>
<p>图6 Point-BERT Pipeline</p>
</div>
<h4><a id="2-1-2-local-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1.2 Local Transformer</h4>
<p>与全局Transformer相比，局部Transformer更关注局部patch而非全局点云上的特征聚合。</p>
<p><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Point_Transformer_ICCV_2021_paper.pdf" title="Point-Transformer">Point Transformer</a>采用<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">PointNet++</a>分层架构进行点云分类和分割。他更关注局部patch处理，采用局部Transformer块代替PointNet++中的共享MLP块。并且PT使用的自注意力算子是<a href="https://arxiv.org/pdf/2004.13621.pdf" title="vector attention">vector attention</a>而非scalar attention，<strong>vector attention</strong>的优点是其支持以通道的方式而非对整个特征向量分配注意力权重。</p>
<div style="text-align: center">
<img src="media/17119019748705/15.png"/>
<p>图7 Point Transformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2012.11409.pdf" title="Pointformer">Pointformer</a>将Transformer块提取的局部和全局特征结合起来进行3D对象检测。它主要由局部Transformer(LT)块、全局Transformer(GT)块和局部-全局Transformer(LGT)块三种模块构成。其中LT块在<a href="https://proceedings.neurips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf" title="PointNet++">FPS</a>生成的每个质心点邻域中应用稠密自注意力操作；GT块以整个点云作为输入，通过自注意力机制学习全局上下文感知特征；<strong>LGT</strong>块采用多尺度交叉注意力模块，将LT的输出作为query，将GT的输出作为key和value进行注意力操作，在LT的局部特征和GT的全局特征之间产生联系。所有质心点都可以用来整合全局信息，从而实现有效的全局特征学习。</p>
<div style="text-align: center">
<img src="media/17119019748705/16.png"/>
<p>图8 Pointformer Pipeline</p>
</div>
<p><a href="https://arxiv.org/pdf/2203.14508.pdf" title="Stratified Transformer">Stratified Transformer</a>通过3D体素化将点云分割成一组不重叠的立方体窗口，并在每个窗口中执行局部Transformer操作。Stratified Transformer是一种Encoder-Decoder架构。其中Encoder是由多个阶段组成的分层结构，每个阶段都具有两个连续的Transformer块，前一个块通过<strong>SSA</strong>（分层自注意力）来捕获长程和短程依赖性，后一个块通过<strong>Shifted SSA</strong>（带滑窗的分层自注意力）来进一步加强不同独立窗口之间的联系。Decoder中，Encoder特征类似于U-Net的方式逐层上采样变得更密集。</p>
<div style="text-align: center">
<img src="media/17119019748705/17.png"/>
<p>图9 Stratified Transformer Pipeline</p>
</div>
<p>为了解决局部Transformer捕获全局信息较弱的问题，SSA为每个query point生成密集的局部key point和稀疏的远程key point。其中前者在key point所属的窗口中生成，后者是通过对整个输入点云进行下采样后，在更大的窗口中生成的。此时query point的感受野就不再局限于局部窗口，使SSA可以捕获全局信息。另外要注意的是，Stratified Transformer在初始的Point Embedding阶段执行了<a href="https://arxiv.org/pdf/1904.08889.pdf" title="KPConv">KPConv</a>嵌入，以便能更好的提取输入点云的局部几何信息。</p>
<h3><a id="2-2-operating-space" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2 Operating Space</h3>
<p>在以操作规模分类的Transformer网络中，Point-wise Transformer注重不同<strong>point</strong>之间的相似性；而Channel-wise Transformer沿<strong>channel</strong>分配权重。其Query与Key之间的attention可以分别表示为如下形式：</p>
<p>\( \begin{align}  \operatorname{Point-wise Attn}(Q, K)=\operatorname{Softmax}\left(\frac{Q K^{T}}{\sqrt{C_{K}}}\right)   \end{align}\)</p>
<p>\( \begin{align}  \operatorname{Channel-wise Attn}(Q, K)=\operatorname{Softmax}\left(\frac{Q ^{T} K}{\sqrt{C_{K}}}\right)   \end{align}\)</p>
<p>其中\(Point-wise Attn\in R^{N\times N}, Channel-wise Attn\in R^{C_{K}\times C_{K}}\)</p>
<h4><a id="2-2-1-point-wise-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.1 Point-wise Transformer</h4>
<p>Point-wise Transformer旨在研究点之间的空间相似性，其输出特征是所有输入特征的加权和。由于2.1节中所有的全局或局部Transformer都是直接对点进行操作和分类的，所以其均可以视为Point-wise Transformer。</p>
<p><a href="https://arxiv.org/pdf/2112.04863.pdf" title="3D Medical Point Transformer">3D Medical Point Transformer</a>是一种用于医学点云分析的Transformer架构。它包括一个用于分类的分层point-wise transformer和一个用于分割的统一尺度point-wise transformer，每个Transformer块都集成了卷积运算，并在该块之前添加了使用<a href="https://arxiv.org/pdf/1801.07829.pdf" title="DGCNN">DGCNN</a>实现的局部特征提取模块。为了针对医学领域训练样本不足的问题，3DMedPT提出了一个MGR（多图推理）的模块用来丰富特征表示。</p>
<div style="text-align: center">
<img src="media/17119019748705/18.png"/>
<p>图10 3D Medical Point Transformer Pipeline</p>
</div>
<h4><a id="2-2-2-channel-wise-transformer" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2.2 Channel-wise Transformer</h4>
<p>Channel-wise Transformer专注于研究不同特征通道之间的相似性从而改进上下文信息建模。</p>
<p><a href="https://arxiv.org/pdf/1911.12885.pdf" title="CAA">GBNPCC</a>利用纠错反馈结构的思想，提出了一种用于局部特征捕获的反投影模块。它设计了一个通道式亲和力注意力（CAA）模块，以实现更好的特征表示。具体来说，CAA 模块由两个模块组成：紧凑通道比较器 (CCC) 模块和通道亲和性估计器 (CAE) 模块。 CCC模块可以生成通道空间中的相似度矩阵。 CAE模块进一步计算了一个亲和力矩阵，其中具有较高注意力值的元素代表相应两个通道的较低相似度。 此操作可以锐化注意力权重并避免聚集相似/冗余信息。 因此，输出特征的每个通道都与其他不同的通道有足够的交互。</p>
<div style="text-align: center">
<img src="media/17119019748705/19.png"/>
<p>图11 GBNPCC Pipeline</p>
</div>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
            💗 This Website is made for my girlfriend Lanyi Zhang. 💗
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script>window.MathJax = {     tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } ,     startup: {     pageReady() {       return MathJax.startup.defaultPageReady().then(function () {          window.mweb_mathjax_ready_val = 'yes';          if(window.mweb_mathjax_ready !== undefined){ mweb_mathjax_ready(); }       });     }   }};document.addEventListener('DOMContentLoaded', function(event) {    if (typeof Prism != 'undefined') {         Prism.highlightAll();     }});window.mweb_mathjax_ready_val = '';function theMWebMathJaxRenderIsReady(key){ return window.mweb_mathjax_ready_val; }</script><script>window.MathJax = { tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } }; </script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>


  
    




  </body>
</html>
