<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    LoReFT-Llama3-8B-Base-Commonsense-170k - Prepare for the FUTURE
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Prepare for the FUTURE" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            LoReFT-Llama3-8B-Base-Commonsense-170k   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/05/03</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_Llama3%20ReFTEng%20vs%20PEFT.html'>#Llama3 ReFTEng vs PEFT</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <h2><a id="1-prepare" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1 Prepare</h2>
<p>虽然用实验室的服务器让我遇到了很多问题。。。然而这根本难不倒我，在找 Hu 学姐要到 autodl 账号后，便申请了一个 L20 显卡的实例（内存整整 48G omg），愉快的开始训练！！！</p>
<h3><a id="1-1-preprocess" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.1 Preprocess</h3>
<p>首先将 <code>pyreft</code>git 到 /root/autodl-tmp（因为是扩容盘，容量大）中，并修改 huggingface 的环境变量：</p>
<pre><code class="language-shell">cd /root/autodl-tmp

git clone https://github.com/stanfordnlp/pyreft.git

# 修改.bashrc
# &gt;&gt;&gt; huggingface init &gt;&gt;&gt;
export HF_DATASETS_CACHE=/root/autodl-tmp/.cache
export HF_CACHE_DIR=/root/autodl-tmp/.cache
export HF_HOME=/root/autodl-tmp/.cache/huggingface
export HF_HUB_CACHE=/root/autodl-tmp/.cache/huggingface/hub
export HF_ENDPOINT=https://hf-mirror.com/meta-llama
export HF_TOKEN=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
# &lt;&lt;&lt; huggingface init &lt;&lt;&lt;
</code></pre>
<h3><a id="1-2-conda" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.2 Conda</h3>
<p>创建虚拟环境：</p>
<pre><code class="language-shell">conda create -n &quot;LoReFT&quot; python=3.9

# 首次需要该命令，否则 conda activate *** 会报错
source activate

conda activate LoReFT
</code></pre>
<p><br />
接着在 conda 虚拟环境中安装 torch 和 pyreft：（需要指定 conda 环境下的 pip 进行安装）</p>
<pre><code class="language-shell"># 安装 pytorch
/root/miniconda3/envs/LoReFT/bin/pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# 安装 pyreft
/root/miniconda3/envs/LoReFT/bin/pip install pyreft
</code></pre>
<p><br />
此时 conda 安装的包及版本如下：</p>
<pre><code class="language-shell">conda list
# packages in environment at /root/miniconda3/envs/LoReFT:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
_openmp_mutex             5.1                       1_gnu    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
accelerate                0.29.3                   pypi_0    pypi
aiohttp                   3.9.5                    pypi_0    pypi
aiosignal                 1.3.1                    pypi_0    pypi
annotated-types           0.6.0                    pypi_0    pypi
anyio                     4.3.0                    pypi_0    pypi
appdirs                   1.4.4                    pypi_0    pypi
argon2-cffi               23.1.0                   pypi_0    pypi
argon2-cffi-bindings      21.2.0                   pypi_0    pypi
arrow                     1.3.0                    pypi_0    pypi
asttokens                 2.4.1                    pypi_0    pypi
async-lru                 2.0.4                    pypi_0    pypi
async-timeout             4.0.3                    pypi_0    pypi
attrs                     23.2.0                   pypi_0    pypi
babel                     2.14.0                   pypi_0    pypi
beautifulsoup4            4.12.3                   pypi_0    pypi
bleach                    6.1.0                    pypi_0    pypi
ca-certificates           2024.3.11            h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
cachetools                5.3.3                    pypi_0    pypi
certifi                   2022.12.7                pypi_0    pypi
cffi                      1.16.0                   pypi_0    pypi
charset-normalizer        2.1.1                    pypi_0    pypi
click                     8.1.7                    pypi_0    pypi
comm                      0.2.2                    pypi_0    pypi
contourpy                 1.2.1                    pypi_0    pypi
cycler                    0.12.1                   pypi_0    pypi
dacite                    1.8.1                    pypi_0    pypi
datasets                  2.18.0                   pypi_0    pypi
debugpy                   1.8.1                    pypi_0    pypi
decorator                 5.1.1                    pypi_0    pypi
defusedxml                0.7.1                    pypi_0    pypi
dill                      0.3.8                    pypi_0    pypi
docker-pycreds            0.4.0                    pypi_0    pypi
evaluate                  0.4.2                    pypi_0    pypi
exceptiongroup            1.2.1                    pypi_0    pypi
executing                 2.0.1                    pypi_0    pypi
fastjsonschema            2.19.1                   pypi_0    pypi
filelock                  3.13.1                   pypi_0    pypi
fonttools                 4.51.0                   pypi_0    pypi
fqdn                      1.5.1                    pypi_0    pypi
frozenlist                1.4.1                    pypi_0    pypi
fsspec                    2024.2.0                 pypi_0    pypi
gcsfs                     2024.2.0                 pypi_0    pypi
gitdb                     4.0.11                   pypi_0    pypi
gitpython                 3.1.43                   pypi_0    pypi
google-api-core           2.19.0                   pypi_0    pypi
google-auth               2.29.0                   pypi_0    pypi
google-auth-oauthlib      1.2.0                    pypi_0    pypi
google-cloud-core         2.4.1                    pypi_0    pypi
google-cloud-storage      2.16.0                   pypi_0    pypi
google-crc32c             1.5.0                    pypi_0    pypi
google-resumable-media    2.7.0                    pypi_0    pypi
googleapis-common-protos  1.63.0                   pypi_0    pypi
h11                       0.14.0                   pypi_0    pypi
htmlmin                   0.1.12                   pypi_0    pypi
httpcore                  1.0.5                    pypi_0    pypi
httpx                     0.27.0                   pypi_0    pypi
huggingface-hub           0.20.3                   pypi_0    pypi
idna                      3.4                      pypi_0    pypi
imagehash                 4.3.1                    pypi_0    pypi
importlib-metadata        7.1.0                    pypi_0    pypi
importlib-resources       6.4.0                    pypi_0    pypi
ipykernel                 6.29.4                   pypi_0    pypi
ipython                   8.18.1                   pypi_0    pypi
ipywidgets                8.1.2                    pypi_0    pypi
isoduration               20.11.0                  pypi_0    pypi
jedi                      0.19.1                   pypi_0    pypi
jinja2                    3.1.3                    pypi_0    pypi
joblib                    1.4.2                    pypi_0    pypi
json5                     0.9.25                   pypi_0    pypi
jsonpointer               2.4                      pypi_0    pypi
jsonschema                4.22.0                   pypi_0    pypi
jsonschema-specifications 2023.12.1                pypi_0    pypi
jupyter                   1.0.0                    pypi_0    pypi
jupyter-client            8.6.1                    pypi_0    pypi
jupyter-console           6.6.3                    pypi_0    pypi
jupyter-core              5.7.2                    pypi_0    pypi
jupyter-events            0.10.0                   pypi_0    pypi
jupyter-lsp               2.2.5                    pypi_0    pypi
jupyter-server            2.14.0                   pypi_0    pypi
jupyter-server-terminals  0.5.3                    pypi_0    pypi
jupyterlab                4.1.8                    pypi_0    pypi
jupyterlab-pygments       0.3.0                    pypi_0    pypi
jupyterlab-server         2.27.1                   pypi_0    pypi
jupyterlab-widgets        3.0.10                   pypi_0    pypi
kiwisolver                1.4.5                    pypi_0    pypi
ld_impl_linux-64          2.38                 h1181459_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libffi                    3.4.4                h6a678d5_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libgcc-ng                 11.2.0               h1234567_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libgomp                   11.2.0               h1234567_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
libstdcxx-ng              11.2.0               h1234567_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
llvmlite                  0.42.0                   pypi_0    pypi
markupsafe                2.1.5                    pypi_0    pypi
matplotlib                3.8.4                    pypi_0    pypi
matplotlib-inline         0.1.7                    pypi_0    pypi
mistune                   3.0.2                    pypi_0    pypi
mizani                    0.11.2                   pypi_0    pypi
mpmath                    1.3.0                    pypi_0    pypi
multidict                 6.0.5                    pypi_0    pypi
multimethod               1.11.2                   pypi_0    pypi
multiprocess              0.70.16                  pypi_0    pypi
nbclient                  0.10.0                   pypi_0    pypi
nbconvert                 7.16.4                   pypi_0    pypi
nbformat                  5.10.4                   pypi_0    pypi
ncurses                   6.4                  h6a678d5_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
nest-asyncio              1.6.0                    pypi_0    pypi
networkx                  3.2.1                    pypi_0    pypi
notebook                  7.1.3                    pypi_0    pypi
notebook-shim             0.2.4                    pypi_0    pypi
numba                     0.59.1                   pypi_0    pypi
numpy                     1.26.4                   pypi_0    pypi
oauthlib                  3.2.2                    pypi_0    pypi
openssl                   3.0.13               h7f8727e_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
overrides                 7.7.0                    pypi_0    pypi
packaging                 24.0                     pypi_0    pypi
pandas                    2.2.2                    pypi_0    pypi
pandocfilters             1.5.1                    pypi_0    pypi
parso                     0.8.4                    pypi_0    pypi
patsy                     0.5.6                    pypi_0    pypi
pexpect                   4.9.0                    pypi_0    pypi
phik                      0.12.4                   pypi_0    pypi
pillow                    10.2.0                   pypi_0    pypi
pip                       23.3.1           py39h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
platformdirs              4.2.1                    pypi_0    pypi
plotnine                  0.13.5                   pypi_0    pypi
prometheus-client         0.20.0                   pypi_0    pypi
prompt-toolkit            3.0.43                   pypi_0    pypi
proto-plus                1.23.0                   pypi_0    pypi
protobuf                  4.25.3                   pypi_0    pypi
psutil                    5.9.8                    pypi_0    pypi
ptyprocess                0.7.0                    pypi_0    pypi
pure-eval                 0.2.2                    pypi_0    pypi
pyarrow                   16.0.0                   pypi_0    pypi
pyarrow-hotfix            0.6                      pypi_0    pypi
pyasn1                    0.6.0                    pypi_0    pypi
pyasn1-modules            0.4.0                    pypi_0    pypi
pycparser                 2.22                     pypi_0    pypi
pydantic                  2.7.1                    pypi_0    pypi
pydantic-core             2.18.2                   pypi_0    pypi
pygments                  2.17.2                   pypi_0    pypi
pyparsing                 3.1.2                    pypi_0    pypi
pyreft                    0.0.5                    pypi_0    pypi
python                    3.9.19               h955ad1f_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
python-dateutil           2.9.0.post0              pypi_0    pypi
python-json-logger        2.0.7                    pypi_0    pypi
pytz                      2024.1                   pypi_0    pypi
pyvene                    0.1.1                    pypi_0    pypi
pywavelets                1.6.0                    pypi_0    pypi
pyyaml                    6.0.1                    pypi_0    pypi
pyzmq                     26.0.3                   pypi_0    pypi
qtconsole                 5.5.1                    pypi_0    pypi
qtpy                      2.4.1                    pypi_0    pypi
readline                  8.2                  h5eee18b_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
referencing               0.35.1                   pypi_0    pypi
regex                     2024.4.28                pypi_0    pypi
requests                  2.31.0                   pypi_0    pypi
requests-oauthlib         2.0.0                    pypi_0    pypi
rfc3339-validator         0.1.4                    pypi_0    pypi
rfc3986-validator         0.1.1                    pypi_0    pypi
rpds-py                   0.18.0                   pypi_0    pypi
rsa                       4.9                      pypi_0    pypi
safetensors               0.4.3                    pypi_0    pypi
scikit-learn              1.4.2                    pypi_0    pypi
scipy                     1.11.4                   pypi_0    pypi
seaborn                   0.12.2                   pypi_0    pypi
send2trash                1.8.3                    pypi_0    pypi
sentencepiece             0.2.0                    pypi_0    pypi
sentry-sdk                2.0.1                    pypi_0    pypi
setproctitle              1.3.3                    pypi_0    pypi
setuptools                68.2.2           py39h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
six                       1.16.0                   pypi_0    pypi
smmap                     5.0.1                    pypi_0    pypi
sniffio                   1.3.1                    pypi_0    pypi
soupsieve                 2.5                      pypi_0    pypi
sqlite                    3.45.3               h5eee18b_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
stack-data                0.6.3                    pypi_0    pypi
statsmodels               0.14.2                   pypi_0    pypi
sympy                     1.12                     pypi_0    pypi
terminado                 0.18.1                   pypi_0    pypi
threadpoolctl             3.5.0                    pypi_0    pypi
tinycss2                  1.3.0                    pypi_0    pypi
tk                        8.6.12               h1ccaba5_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
tokenizers                0.19.1                   pypi_0    pypi
tomli                     2.0.1                    pypi_0    pypi
torch                     2.1.0+cu118              pypi_0    pypi
torchaudio                2.1.0+cu118              pypi_0    pypi
torchvision               0.16.0+cu118             pypi_0    pypi
tornado                   6.4                      pypi_0    pypi
tqdm                      4.66.4                   pypi_0    pypi
traitlets                 5.14.3                   pypi_0    pypi
transformers              4.40.1                   pypi_0    pypi
triton                    2.1.0                    pypi_0    pypi
typeguard                 4.2.1                    pypi_0    pypi
types-python-dateutil     2.9.0.20240316           pypi_0    pypi
typing-extensions         4.11.0                   pypi_0    pypi
tzdata                    2024.1                   pypi_0    pypi
uri-template              1.3.0                    pypi_0    pypi
urllib3                   1.26.13                  pypi_0    pypi
visions                   0.7.6                    pypi_0    pypi
wandb                     0.16.6                   pypi_0    pypi
wcwidth                   0.2.13                   pypi_0    pypi
webcolors                 1.13                     pypi_0    pypi
webencodings              0.5.1                    pypi_0    pypi
websocket-client          1.8.0                    pypi_0    pypi
wheel                     0.41.2           py39h06a4308_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
widgetsnbextension        4.0.10                   pypi_0    pypi
wordcloud                 1.9.3                    pypi_0    pypi
xxhash                    3.4.1                    pypi_0    pypi
xz                        5.4.6                h5eee18b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
yarl                      1.9.4                    pypi_0    pypi
ydata-profiling           4.7.0                    pypi_0    pypi
zipp                      3.18.1                   pypi_0    pypi
zlib                      1.2.13               h5eee18b_1    https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
</code></pre>
<h3><a id="1-3-wandb" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1.3 Wandb</h3>
<p>安装 wandb，结果发现已经有了，所以直接 login</p>
<pre><code class="language-shell"># 安装 wandb
/root/miniconda3/envs/LoReFT/bin/pip install wandb

# 登录 wandb
wandb login
</code></pre>
<h2><a id="2-data-loading" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2 Data Loading</h2>
<p>加载数据：</p>
<pre><code class="language-shell">cd examples/loreft

bash load_datasets.sh
</code></pre>
<h2><a id="3-debug" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3 Debug</h2>
<p>首先需要在 train.py 中添加：</p>
<pre><code class="language-python">os.environ['CUDA_VISIBLE_DEVICES']='0'
</code></pre>
<p><br />
并作如下修改：</p>
<pre><code class="language-shell"># 原始代码
if &quot;Meta-Llama-3-8B&quot; in model_name:
    tokenizer = AutoTokenizer.from_pretrained(
        &quot;meta-llama/Meta-Llama-3-8B&quot;, # use instruct for the template.
        model_max_length=max_length,
        padding_side=&quot;right&quot;,
        use_fast=False,
    )
elif &quot;Meta-Llama-3-8B-Instruct&quot; in model_name:
    tokenizer = AutoTokenizer.from_pretrained(
        &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;, # use instruct for the template.
        model_max_length=max_length,
        padding_side=&quot;right&quot;,
        use_fast=False,
    )
else:
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        model_max_length=max_length,
        padding_side=&quot;right&quot;,
        use_fast=False,
    )

# 修改后代码
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    model_max_length=max_length,
    padding_side=&quot;right&quot;,
    use_fast=False,
)

</code></pre>
<p><br />
并在 wandb 处作如下修改：</p>
<pre><code class="language-python"># 原始代码
# start wandb logging
if is_wandb:
    run = wandb.init(project=f&quot;{wandb_proj}_{task}&quot;, 
        entity=wandb_name,
        name=run_name,
        dir=wandb_dir,
    )run.summary.update(vars(args))
    wandb.log({&quot;train/n_params&quot;: n_params})


# 修改后代码
# start wandb logging
if is_wandb:
    run = wandb.init(project=f&quot;{wandb_proj}&quot;, 
        entity=wandb_name,
        name=run_name,
        dir=wandb_dir,
    )run.summary.update(vars(args))
    wandb.log({&quot;train/n_params&quot;: n_params})

</code></pre>
<p><br />
接着运行命令：</p>
<pre><code class="language-shell">python train.py -task commonsense \
-data_dir dataset \
-model Meta-Llama-3-8B \
-seed 42 \
-l all -r 8 -p f7+l7 -e 6 -lr 9e-4 \
-is_wandb \
-wandb_name prada-lab \
-type LoreftIntervention \
-gradient_accumulation_steps 2 \
-batch_size 16 \
-eval_batch_size 4 \
--dropout 0.00 \
--test_split test \
--use_normalized_template \
--share_weights \
--warmup_ratio 0.1 \
--wandb_proj just_fot_test \
--greedy_decoding
</code></pre>
<p><br />
注：~~ 若 <code>Downloading shards</code> 环节出现错误，可以在 <code>AutoModelForCausalLM.from_pretrained()</code> 参数重添加 <code>force_download=True, resume_download=False</code> 进行避免。~~ 千万不要这样，否则会强制重新下载模型文件并禁用断点续传，每次都要重新下载模型参数文件。</p>
<p>然而出现报错：</p>
<pre><code class="language-shell">task: commonsense, model: Meta-Llama-3-8B, intervention_type: LoreftIntervention, layers: all, rank: 8, position: f7+l7, epoch: 6, train_on_inputs: False, max_length: 512, allow_cls_grad: False
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
adding a special padding token...
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True, 'test_split': 'test'}
loading data for dataset:  dataset/commonsense_170k/train.json
100%|██████████████████████████████████████████████████████| 170420/170420 [02:56&lt;00:00, 966.91it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/boolq/test.json
100%|█████████████████████████████████████████████████████████| 3270/3270 [00:00&lt;00:00, 3333.91it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/piqa/test.json
100%|█████████████████████████████████████████████████████████| 1838/1838 [00:00&lt;00:00, 2022.27it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/social_i_qa/test.json
100%|█████████████████████████████████████████████████████████| 1954/1954 [00:00&lt;00:00, 2284.58it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/hellaswag/test.json
100%|████████████████████████████████████████████████████████| 10042/10042 [00:10&lt;00:00, 939.16it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/winogrande/test.json
100%|█████████████████████████████████████████████████████████| 1267/1267 [00:00&lt;00:00, 2579.92it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/ARC-Easy/test.json
100%|█████████████████████████████████████████████████████████| 2376/2376 [00:01&lt;00:00, 2177.32it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/ARC-Challenge/test.json
100%|█████████████████████████████████████████████████████████| 1172/1172 [00:00&lt;00:00, 2008.07it/s]
{'num_interventions': 32, 'position': 'f7+l7', 'share_weights': True}
loading data for dataset:  dataset/openbookqa/test.json
100%|███████████████████████████████████████████████████████████| 500/500 [00:00&lt;00:00, 2321.57it/s]
model-00001-of-00004.safetensors: 100%|████████████████████████| 4.98G/4.98G [07:40&lt;00:00, 10.8MB/s]
model-00002-of-00004.safetensors: 100%|████████████████████████| 5.00G/5.00G [06:17&lt;00:00, 13.2MB/s]
model-00003-of-00004.safetensors: 100%|████████████████████████| 4.92G/4.92G [04:59&lt;00:00, 16.4MB/s]
model-00004-of-00004.safetensors: 100%|████████████████████████| 1.17G/1.17G [01:05&lt;00:00, 17.9MB/s]
Downloading shards: 100%|████████████████████████████████████████████| 4/4 [20:08&lt;00:00, 302.02s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████| 4/4 [00:09&lt;00:00,  2.37s/it]
generation_config.json: 100%|██████████████████████████████████████| 177/177 [00:00&lt;00:00, 34.6kB/s]
trainable intervention params: 2,097,408 || trainable model params: 0
model params: 8,030,269,440 || trainable%: 0.0261187749137344
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Currently logged in as: nnyy (prada-lab). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in wandb/wandb/run-20240504_021800-o4lc9d0b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Meta-Llama-3-8B.commonsense.20240504015342528160
wandb: ⭐️ View project at https://wandb.ai/prada-lab/just_fot_test
wandb: 🚀 View run at https://wandb.ai/prada-lab/just_fot_test/runs/o4lc9d0b
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|                                                                     | 0/31956 [00:00&lt;?, ?it/s]Traceback (most recent call last):
  File &quot;/root/autodl-tmp/pyreft/examples/loreft/train.py&quot;, line 497, in &lt;module&gt;
    main()
  File &quot;/root/autodl-tmp/pyreft/examples/loreft/train.py&quot;, line 493, in main
    finetune(**vars(args), args=args)
  File &quot;/root/autodl-tmp/pyreft/examples/loreft/train.py&quot;, line 392, in finetune
    trainer.train()
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 1859, in train
    return inner_training_loop(
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 2203, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 3138, in training_step
    loss = self.compute_loss(model, inputs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/pyreft/reft_trainer.py&quot;, line 82, in compute_loss
    _, cf_outputs = intervenable(
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/pyvene/models/intervenable_base.py&quot;, line 1460, in forward
    raise e
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/pyvene/models/intervenable_base.py&quot;, line 1443, in forward
    counterfactual_outputs = self.model(**base, labels=labels)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py&quot;, line 1208, in forward
    outputs = self.model(
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py&quot;, line 1018, in forward
    layer_outputs = decoder_layer(
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py&quot;, line 756, in forward
    hidden_states = self.mlp(hidden_states)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py&quot;, line 240, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/module.py&quot;, line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File &quot;/root/miniconda3/envs/LoReFT/lib/python3.9/site-packages/torch/nn/modules/linear.py&quot;, line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 47.50 GiB of which 110.56 MiB is free. Process 886451 has 47.39 GiB memory in use. Of the allocated memory 45.68 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: | 0.060 MB of 0.060 MB uploaded
wandb: Run history:
wandb: train/n_params ▁
wandb: 
wandb: Run summary:
wandb:                    add_bias False
wandb:              allow_cls_grad False
wandb:                  batch_size 16
wandb:                    data_dir dataset
wandb:                     dropout 0.0
wandb:                       dtype bfloat16
wandb:                      epochs 6
wandb:             eval_batch_size 4
wandb: gradient_accumulation_steps 2
wandb:             greedy_decoding True
wandb:           intervention_type LoreftIntervention
wandb:                    is_wandb True
wandb:                      layers all
wandb:               logging_steps 1
wandb:                          lr 0.0009
wandb:                  max_length 512
wandb:       metric_for_best_model accuracy
wandb:                       model Meta-Llama-3-8B
wandb:                  output_dir ./official_results
wandb:                    position f7+l7
wandb:                        rank 8
wandb:                  save_model False
wandb:                    schedule linear
wandb:                        seed 42
wandb:               share_weights True
wandb:                        task commonsense
wandb:                  test_split test
wandb:              train/n_params 2097408
wandb:             train_on_inputs False
wandb:     use_normalized_template True
wandb:                   wandb_dir wandb
wandb:                  wandb_name prada-lab
wandb:                  wandb_proj just_fot_test
wandb:                warmup_ratio 0.1
wandb:                weight_decay 0.0
wandb: 
wandb: 🚀 View run Meta-Llama-3-8B.commonsense.20240504015342528160 at: https://wandb.ai/prada-lab/just_fot_test/runs/o4lc9d0b
wandb: ⭐️ View project at: https://wandb.ai/prada-lab/just_fot_test
wandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: wandb/wandb/run-20240504_021800-o4lc9d0b/logs
</code></pre>
<p><br />
为了避免可能的死锁问题，在 train.py 中新增 <code>os.environ[&quot;TOKENIZERS_PARALLELISM&quot;] = &quot;false&quot;</code>，然而还是发生 OOM 情况。故采用较小的 batch_size 进行实验。</p>
<h2><a id="train" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train</h2>
<p>终于，在我将训练时 batch_size 调小为 4 的时候，训练成功了！！！！！（相应的 eval_batch_size 也减少为 2）</p>
<blockquote>
<p>注：在修改 batch_size 的同时，也要修改 gradient_accumulation_steps 的大小，简单来说，batch_size 和 gradient_accumulation_steps 共同决定采用多少条数据进行一次梯度更新（\(数据量 = batch\_size \times gradient\_accumulation\_steps\)）。因此对 batch_size 减小，相应的要对 gradient_accumulation_step 增大。</p>
</blockquote>
<pre><code class="language-shell">python train.py -task commonsense \
-data_dir dataset \
-model Meta-Llama-3-8B \
-seed 42 \
-l all -r 8 -p f7+l7 -e 6 -lr 9e-4 \
-type LoreftIntervention \
-batch_size 4 \
-gradient_accumulation_steps 8 \
-eval_batch_size 2 \
--dropout 0.00 \
--test_split test \
--use_normalized_template \
--share_weights \
--warmup_ratio 0.1 \
--greedy_decoding \
-is_wandb \
-wandb_name prada-lab \
--wandb_proj just_fot_test
</code></pre>
<p><br />
为了避免 ssh 断连，我们采用 screen 的方式避免：</p>
<pre><code class="language-shell"># （在当前 &quot;LoReFT&quot; 的 conda 虚拟环境下）新建一个 screen，名为 LoReFT-llama3-8B-Commonsense
screen -S LoReFT-llama3-8B-Base-Commonsense

# 运行程序
python train.py -task commonsense \
-data_dir dataset \
-model Meta-Llama-3-8B \
-seed 42 \
-l all -r 8 -p f7+l7 -e 6 -lr 9e-4 \
-type LoreftIntervention \
-batch_size 4 \
-gradient_accumulation_steps 8 \
-eval_batch_size 2 \
--dropout 0.00 \
--test_split test \
--use_normalized_template \
--share_weights \
--warmup_ratio 0.1 \
--greedy_decoding \
-is_wandb \
-wandb_name prada-lab \
--wandb_proj just_fot_test
</code></pre>
<p><br />
要临时关闭该 screen 窗口，只需在该窗口下执行 <code>control + A + D (for mac)</code> 即可，若要恢复，可以采取如下方式：</p>
<pre><code class="language-shell"># 查看当前已有的 screen 窗口
screen -ls
There is a screen on:
	5706.LoReFT-llama3-8B-Base-Commonsense	(05/04/24 12:45:29)	(Detached)
1 Socket in /run/screen/S-root.

# 恢复该窗口
screen -r 5706
</code></pre>
<p><br />
接下来就是安心等待了，希望训练平平安安...</p>
<h2><a id="result" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Result</h2>
<p>经过接近 50 个小时的训练，终于微调结束了！！！</p>
<h3><a id="evaluation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluation</h3>
<p>该部分记录 llama3-8b-base 在微调commonsense task时的测试得分情况。</p>
<div style="text-align: center">
<img src="media/17147464283285/ARC-Challenge.png"/>
<p>图 1  ARC-Challenge Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/ARC-Easy.png"/>
<p>图 2 ARC-Easy Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/boolq.png"/>
<p>图 3 boolq Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/hellaswag.png"/>
<p>图 4 hellaswag Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/openbookqa.png"/>
<p>图 5 openbookqa Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/piqa.png"/>
<p>图 6  piqa Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/social_i_qa.png"/>
<p>图 7 social_i_qa Evaluation</p>
</div>
<div style="text-align: center">
<img src="media/17147464283285/winogrande.png"/>
<p>图 8 winogrande Evaluation</p>
</div>
<p>各部分详细得分见下表所示：</p>
<table>
<thead>
<tr>
<th>dataset</th>
<th>score</th>
</tr>
</thead>
<tbody>
<tr>
<td>pipa</td>
<td>0.8988</td>
</tr>
<tr>
<td>winogrande</td>
<td>0.8777</td>
</tr>
<tr>
<td>boolq</td>
<td>0.7538</td>
</tr>
<tr>
<td>ARC-Easy</td>
<td>0.9217</td>
</tr>
<tr>
<td>hellaswag</td>
<td>0.9621</td>
</tr>
<tr>
<td>openbookqa</td>
<td>0.874</td>
</tr>
<tr>
<td>ARC-Challenge</td>
<td>0.8106</td>
</tr>
<tr>
<td>social_i_qa</td>
<td>0.8153</td>
</tr>
</tbody>
</table>
<p>柱状图如下所示：</p>
<div style="text-align: center">
<img src="media/17147464283285/LoReFT-Llama3-8B-Base-Commonsense-170k-Eval-Score.jpg"/>
<p>图 9 LoReFT-Llama3-8B-Base-Commonsense-170k-Eval-Score</p>
</div>
<h3><a id="train" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train</h3>
<p>该部分记录 llama3-8b-base 在微调commonsense task时的训练参数情况。</p>
<p><img src="media/17147464283285/epoch.png" alt="epoch" /></p>
<p><img src="media/17147464283285/global_step.png" alt="global_step" /></p>
<p><img src="media/17147464283285/grad_norm.png" alt="grad_norm" /></p>
<p><img src="media/17147464283285/learning_rate.png" alt="learning_rate" /></p>
<p><img src="media/17147464283285/loss.png" alt="loss" /></p>
<p><img src="media/17147464283285/n_params.png" alt="n_params" /></p>
<h3><a id="system" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>System</h3>
<p>该部分记录 llama3-8b-base 在微调commonsense task时的系统情况。</p>
<p><img src="media/17147464283285/Disk%20I_O%20Utilization%20-MB-.png" alt="Disk I_O Utilization -MB-" /></p>
<p><img src="media/17147464283285/Disk%20Utilization%20-%25-.png" alt="Disk Utilization -%-" /></p>
<p><img src="media/17147464283285/Disk%20Utilization%20-GB-.png" alt="Disk Utilization -GB-" /></p>
<p><img src="media/17147464283285/GPU%20Memory%20Allocated%20-%25-.png" alt="GPU Memory Allocated -%-" /></p>
<p><img src="media/17147464283285/GPU%20Power%20Usage%20-%25-.png" alt="GPU Power Usage -%-" /></p>
<p><img src="media/17147464283285/GPU%20Power%20Usage%20-W-.png" alt="GPU Power Usage -W-" /></p>
<p><img src="media/17147464283285/GPU%20Temp%20-%E2%84%83-.png" alt="GPU Temp -℃-" /></p>
<p><img src="media/17147464283285/GPU%20Time%20Spent%20Accessing%20Memory%20-%25-.png" alt="GPU Time Spent Accessing Memory -%-" /></p>
<p><img src="media/17147464283285/GPU%20Utilization%20-%25-.png" alt="GPU Utilization -%-" /></p>
<p><img src="media/17147464283285/gpu.0.memoryAllocatedBytes.png" alt="gpu.0.memoryAllocatedBytes" /></p>
<p><img src="media/17147464283285/Network%20Traffic%20-bytes-.png" alt="Network Traffic -bytes-" /></p>
<p><img src="media/17147464283285/Process%20CPU%20Threads%20In%20Use.png" alt="Process CPU Threads In Use" /></p>
<p><img src="media/17147464283285/Process%20CPU%20Utilization%20-%25-.png" alt="Process CPU Utilization -%-" /></p>
<p><img src="media/17147464283285/Process%20Memory%20Available%20-non-swap-%20-MB-.png" alt="Process Memory Available -non-swap- -MB-" /></p>
<p><img src="media/17147464283285/Process%20Memory%20In%20Use%20-non-swap-%20-%25-.png" alt="Process Memory In Use -non-swap- -%-" /></p>
<p><img src="media/17147464283285/Process%20Memory%20In%20Use%20-non-swap-%20-MB-.png" alt="Process Memory In Use -non-swap- -MB-" /></p>
<p><img src="media/17147464283285/System%20CPU%20Utilization%20-per%20core-%20-%25-.png" alt="System CPU Utilization -per core- -%-" /></p>
<p><img src="media/17147464283285/System%20Memory%20Utilization%20-%25-.png" alt="System Memory Utilization -%-" /></p>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script>!function(){if("undefined"!=typeof Prism&&"undefined"!=typeof document){var e=[],t={},n=function(){};Prism.plugins.toolbar={};var a=Prism.plugins.toolbar.registerButton=function(n,a){var r;r="function"==typeof a?a:function(e){var t;return"function"==typeof a.onClick?((t=document.createElement("button")).type="button",t.addEventListener("click",(function(){a.onClick.call(this,e)}))):"string"==typeof a.url?(t=document.createElement("a")).href=a.url:t=document.createElement("span"),a.className&&t.classList.add(a.className),t.textContent=a.text,t},n in t?console.warn('There is a button with the key "'+n+'" registered already.'):e.push(t[n]=r)},r=Prism.plugins.toolbar.hook=function(a){var r=a.element.parentNode;var l=a.element.classList;if(l.contains('language-mermaid') || l.contains('language-echarts') || l.contains('language-plantuml')){return;} if(r&&/pre/i.test(r.nodeName)&&!r.parentNode.classList.contains("code-toolbar")){var o=document.createElement("div");o.classList.add("code-toolbar"),r.parentNode.insertBefore(o,r),o.appendChild(r);var i=document.createElement("div");i.classList.add("toolbar");var l=e,d=function(e){for(;e;){var t=e.getAttribute("data-toolbar-order");if(null!=t)return(t=t.trim()).length?t.split(/\s*,\s*/g):[];e=e.parentElement}}(a.element);d&&(l=d.map((function(e){return t[e]||n}))),l.forEach((function(e){var t=e(a);if(t){var n=document.createElement("div");n.classList.add("toolbar-item"),n.appendChild(t),i.appendChild(n)}})),o.appendChild(i)}};a("label",(function(e){var t=e.element.parentNode;if(t&&/pre/i.test(t.nodeName)&&t.hasAttribute("data-label")){var n,a,r=t.getAttribute("data-label");try{a=document.querySelector("template#"+r)}catch(e){}return a?n=a.content:(t.hasAttribute("data-url")?(n=document.createElement("a")).href=t.getAttribute("data-url"):n=document.createElement("span"),n.textContent=r),n}})),Prism.hooks.add("complete",r)}}();</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.css"><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script><style>div.code-toolbar > .toolbar > .toolbar-item > a, div.code-toolbar > .toolbar > .toolbar-item > button, div.code-toolbar > .toolbar > .toolbar-item > span {padding: 4px .5em; background: #f5f2f0; background: rgba(224, 224, 224, 0.4);}</style><script>window.MathJax = {     tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } ,     startup: {     pageReady() {       return MathJax.startup.defaultPageReady().then(function () {          window.mweb_mathjax_ready_val = 'yes';          if(window.mweb_mathjax_ready !== undefined){ mweb_mathjax_ready(); }       });     }   }};document.addEventListener('DOMContentLoaded', function(event) {    if (typeof Prism != 'undefined') {         Prism.highlightAll();     }});window.mweb_mathjax_ready_val = '';function theMWebMathJaxRenderIsReady(key){ return window.mweb_mathjax_ready_val; }</script><script>window.MathJax = { tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } }; </script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>


  
    




  </body>
</html>
