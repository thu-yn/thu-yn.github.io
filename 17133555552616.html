<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    CT3D Reproduction (spconv==1.2.1) - Prepare for the FUTURE
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Prepare for the FUTURE" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            CT3D Reproduction (spconv==1.2.1)   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/04/17</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_Pointcloud%20in%20Transformer.html'>#Pointcloud in Transformer</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <h2><a id="1-base-info" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1 Base Info</h2>
<p>Conda 环境基本信息：</p>
<table>
<thead>
<tr>
<th style="text-align: center">Name</th>
<th style="text-align: center">Model</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center">python</td>
<td style="text-align: center">3.7</td>
</tr>
<tr>
<td style="text-align: center">cuda</td>
<td style="text-align: center">11.0</td>
</tr>
<tr>
<td style="text-align: center">cudnn</td>
<td style="text-align: center">8.9.2</td>
</tr>
<tr>
<td style="text-align: center">pytorch</td>
<td style="text-align: center">1.7.0</td>
</tr>
<tr>
<td style="text-align: center">cmake</td>
<td style="text-align: center">3.26.4</td>
</tr>
</tbody>
</table>
<pre><code class="language-shell"># 安装cuda
conda install cudatoolkit=11.0 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main

# 安装cudnn
conda install cudnn-8.9.2 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main

# 安装 pytorch
pip install torch==1.7.0+cu110 torchvision==0.8.1+cu110 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html

# 安装cmake
conda install -c anaconda cmake
</code></pre>
<h2><a id="2-spconv-downloading" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2 SPCONV Downloading</h2>
<p>根据<a href="https://blog.csdn.net/weixin_44808890/article/details/125943654?spm=1001.2014.3001.5502" title="web_1">web_1</a>下载<code>spconv==1.2.1</code>。</p>
<pre><code class="language-shell"># git spconv1.2.1版本，此版本是修复版（针对无编译环境直接pip安装.whl文件时报错缺少libcuhash.so问题）
git clone -b build_bug_fix https://github.com/ExpeditionTechnology/spconv.git --recursive

# 由于git后，其目录下third_patry里cutlass, mp11和pybind11始终无法正常下载，因此分别将其git后移动到'spconv/third/party'下

git clone https://github.com/NVIDIA/cutlass.git

git clone https://github.com/boostorg/mp11.git

git clone https://github.com/pybind/pybind11.git
</code></pre>
<h2><a id="3-spconv-compilation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>3 SPCONV Compilation</h2>
<p>编译spconv：</p>
<pre><code class="language-shell"># 进入到git的spconv目录下
cd spconv/

# 编译
python setup.py bdist_wheel
</code></pre>
<p><br />
此处消耗大量时间，查找大量网页修复错误，我们修改的最终版：</p>
<p>针对CMake报错：<code>Failed to detect a default CUDA architecture.</code>在<code>/home/workspace/nanyang/spconv/CmakeLists.txt</code>中第3行加入：</p>
<pre><code class="language-shell">set(CMAKE_CUDA_ARCHITECTURES 60 61 70 75)
</code></pre>
<p><br />
由于编译时，在conda环境中安装的cuda并没有nvcc，因此需要利用服务器上自带的cuda进行编译，我们很幸运的在<code>/usr/local</code>下找到了cuda-11.0文件夹，与我们conda环境中安装的cuda相同，因此我们在<code>/home/workspace/nanyang/spconv/setup.py</code>中的<code>build_extension</code>函数的<code>cmake_args</code>中加入了<code>'-DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.0/bin/nvcc'</code>。</p>
<p>然而产生了报错<code>The CUDA compiler &quot;/usr/local/cuda-11.0/bin/nvcc&quot; is not able to compile a simple test program.</code>。</p>
<p>在这一步卡了非常久的时间，也是查找了很多网页，但是都没有什么效果。最终解决方法：发现<code>/usr/local</code>路径下存在不同的cuda版本：</p>
<pre><code class="language-shell">├── usr
│   ├── local
│   │   │── cuda
│   │   │   │── bin
│   │   │   │   │── nvcc
│   │   │   │   │── ···
│   │   │   │── ···
│   │   │── cuda-10.2
│   │   │   │── bin
│   │   │   │   │── nvcc
│   │   │   │   │── ···
│   │   │   │── ···
│   │   │── cuda-11.0
│   │   │   │── bin
│   │   │   │   │── nvcc
│   │   │   │   │── ···
│   │   │   │── ···
│   │   │── cuda-11.1
│   │   │   │── bin
│   │   │   │   │── nvcc
│   │   │   │   │── ···
│   │   │   │── ···
│   │   │── cuda-11.7
│   │   │   │── bin
│   │   │   │   │── nvcc
│   │   │   │   │── ···
│   │   │   │── ···
│   │   │── ···
│   ├── ···
</code></pre>
<p><br />
出于<a href="https://baike.baidu.com/item/%E6%AD%BB%E9%A9%AC%E5%BD%93%E6%B4%BB%E9%A9%AC%E5%8C%BB/4516476" title="死马当作活马医">死马当作活马医</a>的缘故，尝试将<code>/home/workspace/nanyang/spconv/setup.py</code>中作如下修改：</p>
<pre><code class="language-shell"># 原始代码
-DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.0/bin/nvcc

# 修改后代码
-DCMAKE_CUDA_COMPILER=/usr/local/cuda-11.1/bin/nvcc
</code></pre>
<p><br />
没想到竟然没有 CUDA COMPILER 的报错！但是出现了新的报错如下：</p>
<pre><code class="language-shell">In file included from /home/workspace/nanyang/CT3D/spconv/src/utils/all.cc:16:
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h: In function ‘std::vector&lt;int&gt; spconv::rotate_non_max_suppression_cpu(pybind11::array_t&lt;DType&gt;, pybind11::array_t&lt;int&gt;, pybind11::array_t&lt;DType&gt;, DType)’:
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:133:14: error: ‘cout’ is not a member of ‘std’
  133 |         std::cout &lt;&lt; &quot;box i corners:&quot; &lt;&lt; std::endl;
      |              ^~~~
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:25:1: note: ‘std::cout’ is defined in header ‘&lt;iostream&gt;’; did you forget to ‘#include &lt;iostream&gt;’?
   24 | #include &lt;pybind11/stl.h&gt;
  +++ |+#include &lt;iostream&gt;
   25 | #include &lt;vector&gt;
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:135:16: error: ‘cout’ is not a member of ‘std’
  135 |           std::cout &lt;&lt; box_corners_r(i, k, 0) &lt;&lt; &quot; &quot; &lt;&lt; box_corners_r(i, k, 1)
      |                ^~~~
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:135:16: note: ‘std::cout’ is defined in header ‘&lt;iostream&gt;’; did you forget to ‘#include &lt;iostream&gt;’?
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:138:14: error: ‘cout’ is not a member of ‘std’
  138 |         std::cout &lt;&lt; &quot;box j corners:&quot; &lt;&lt; std::endl;
      |              ^~~~
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:138:14: note: ‘std::cout’ is defined in header ‘&lt;iostream&gt;’; did you forget to ‘#include &lt;iostream&gt;’?
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:140:16: error: ‘cout’ is not a member of ‘std’
  140 |           std::cout &lt;&lt; box_corners_r(j, k, 0) &lt;&lt; &quot; &quot; &lt;&lt; box_corners_r(j, k, 1)
      |                ^~~~
/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h:140:16: note: ‘std::cout’ is defined in header ‘&lt;iostream&gt;’; did you forget to ‘#include &lt;iostream&gt;’?
make[2]: *** [src/utils/CMakeFiles/spconv_utils.dir/build.make:79: src/utils/CMakeFiles/spconv_utils.dir/all.cc.o] Error 1
make[2]: Leaving directory '/home/workspace/nanyang/CT3D/spconv/build/temp.linux-x86_64-cpython-37'
make[1]: *** [CMakeFiles/Makefile2:235: src/utils/CMakeFiles/spconv_utils.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
</code></pre>
<p><br />
显然，报错原因为<code>nms.h</code>中缺少<code>#include &lt;iostream&gt;</code>，将其添加到<code>/home/workspace/nanyang/CT3D/spconv/include/spconv/nms.h</code>第26行后重新编译。编译结果如下，说明成功：</p>
<pre><code class="language-shell">[100%] Built target spconv
make[1]: Leaving directory '/home/workspace/nanyang/CT3D/spconv/build/temp.linux-x86_64-cpython-37'
/home/workspace/nanyang/anaconda3/envs/ct3d/bin/cmake -E cmake_progress_start /home/workspace/nanyang/CT3D/spconv/build/temp.linux-x86_64-cpython-37/CMakeFiles 0
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.
  setuptools.SetuptoolsDeprecationWarning,
installing to build/bdist.linux-x86_64/wheel
running install
running install_lib
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/wheel
creating build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/spconv_utils.cpython-37m-x86_64-linux-gnu.so.1 -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/spconv_utils.cpython-37m-x86_64-linux-gnu.so.1.1 -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/conv.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/__init__.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/identity.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/ops.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/libcuhash.so -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/spconv_utils.cpython-37m-x86_64-linux-gnu.so -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/test_utils.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/functional.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/libspconv.so -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/tables.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/pool.py -&gt; build/bdist.linux-x86_64/wheel/spconv
copying build/lib.linux-x86_64-cpython-37/spconv/modules.py -&gt; build/bdist.linux-x86_64/wheel/spconv
creating build/bdist.linux-x86_64/wheel/spconv/utils
copying build/lib.linux-x86_64-cpython-37/spconv/utils/__init__.py -&gt; build/bdist.linux-x86_64/wheel/spconv/utils
running install_egg_info
running egg_info
creating spconv.egg-info
writing spconv.egg-info/PKG-INFO
writing dependency_links to spconv.egg-info/dependency_links.txt
writing top-level names to spconv.egg-info/top_level.txt
writing manifest file 'spconv.egg-info/SOURCES.txt'
reading manifest file 'spconv.egg-info/SOURCES.txt'
adding license file 'LICENSE'
writing manifest file 'spconv.egg-info/SOURCES.txt'
Copying spconv.egg-info to build/bdist.linux-x86_64/wheel/spconv-1.2.1-py3.7.egg-info
running install_scripts
creating build/bdist.linux-x86_64/wheel/spconv-1.2.1.dist-info/WHEEL
creating 'dist/spconv-1.2.1-cp37-cp37m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it
adding 'spconv/__init__.py'
adding 'spconv/conv.py'
adding 'spconv/functional.py'
adding 'spconv/identity.py'
adding 'spconv/libcuhash.so'
adding 'spconv/libspconv.so'
adding 'spconv/modules.py'
adding 'spconv/ops.py'
adding 'spconv/pool.py'
adding 'spconv/spconv_utils.cpython-37m-x86_64-linux-gnu.so'
adding 'spconv/spconv_utils.cpython-37m-x86_64-linux-gnu.so.1'
adding 'spconv/spconv_utils.cpython-37m-x86_64-linux-gnu.so.1.1'
adding 'spconv/tables.py'
adding 'spconv/test_utils.py'
adding 'spconv/utils/__init__.py'
adding 'spconv-1.2.1.dist-info/LICENSE'
adding 'spconv-1.2.1.dist-info/METADATA'
adding 'spconv-1.2.1.dist-info/WHEEL'
adding 'spconv-1.2.1.dist-info/top_level.txt'
adding 'spconv-1.2.1.dist-info/RECORD'
removing build/bdist.linux-x86_64/wheel
</code></pre>
<p><br />
至此，spconv 1.2.1的初步编译成功。</p>
<h2><a id="4-spconv-installation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>4 SPCONV Installation</h2>
<p>安装spconv：</p>
<pre><code class="language-shell"># 进入到git spconv的路径中
cd dist

# 安装dist中的文件
pip install spconv-1.2.1-cp37-cp37m-linux_x86_64.whl
</code></pre>
<p><br />
输出如下所示，竟然如此轻松就安装完成了。</p>
<pre><code class="language-shell">Processing ./spconv-1.2.1-cp37-cp37m-linux_x86_64.whl
Installing collected packages: spconv
Successfully installed spconv-1.2.1
</code></pre>
<p><br />
在python环境中做如下验证：</p>
<pre><code class="language-shell">Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) 
[GCC 9.4.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import spconv
&gt;&gt;&gt; a = 1
&gt;&gt;&gt; a
1
</code></pre>
<p><br />
验证成功！</p>
<h2><a id="5-source-code-requirements-installation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>5 Source Code Requirements Installation</h2>
<p>下载<a href="https://github.com/hlsheng1/CT3D" title="github: CT3D">CT3D 源码</a>，将 CT3D-master 改名为 CT3D 放到 <code>home/workspace/nanyang/</code> 路径下，即代码路径为 <code>home/workspace/nanyang/CT3D</code>。同时将spconv放入该路径下，变为<code>home/workspace/nanyang/CT3D/spconv</code>。</p>
<p>安装依赖项：<code>pip install -r requirements.txt</code>，下载的相关包如下：</p>
<pre><code class="language-shell">PyWavelets-1.3.0 
easydict-1.13 
imageio-2.31.2 
importlib-metadata-6.7.0 
llvmlite-0.39.1 
networkx-2.6.3 
numba-0.56.4 
packaging-24.0 
protobuf-4.24.4 
pyyaml-6.0.1 
scikit-image-0.19.3 
scipy-1.7.3 
tensorboardX-2.6.2.2 
tifffile-2021.11.2 
tqdm-4.66.2 
zipp-3.15.0
</code></pre>
<h2><a id="6-pcdet-installation" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>6 PCDet Installation</h2>
<p>通过 <code>python setup.py develop</code> 编译库。</p>
<table>
<thead>
<tr>
<th style="text-align: center">Name</th>
<th style="text-align: center">Model</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center">pcdet</td>
<td style="text-align: center">0.3.0+0</td>
</tr>
</tbody>
</table>
<h2><a id="7-generate-data-information" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>7 Generate Data Information</h2>
<p>在路径为 <code>home/workspace/nanyang/CT3D</code> 下，采用如下的代码产生数据信息：</p>
<pre><code class="language-shell">python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml
</code></pre>
<p>首先要对 <code>home/workspace/nanyang/CT3D/pcdet/datasets/kitti/kitti_dataset.py</code> 中数据集的路径进行修改，将其 432-439 行修改为：</p>
<pre><code class="language-shell"># 原始代码
dataset_cfg = EasyDict(yaml.load(open(sys.argv[2])))
ROOT_DIR = (Path(__file__).resolve().parent / '../../../').resolve()
create_kitti_infos(
    dataset_cfg=dataset_cfg,
    class_names=['Car', 'Pedestrian', 'Cyclist'],
    data_path=ROOT_DIR / 'data' / 'kitti',
    save_path=ROOT_DIR / 'data' / 'kitti'
)

# 修改后代码
# 此时路径为 home/share/nanyang/Kitti  
dataset_cfg = EasyDict(yaml.load(open(sys.argv[2]), Loader = yaml.FullLoader))
ROOT_DIR = (Path(__file__).resolve().parent / '../../../../../../share/nanyang/Kitti').resolve()
create_kitti_infos(
    dataset_cfg=dataset_cfg,
    class_names=['Car', 'Pedestrian', 'Cyclist'],
    data_path=ROOT_DIR,
    save_path=ROOT_DIR
)
</code></pre>
<p><br />
一次成功！！！命令行展示如下：</p>
<pre><code class="language-shell">/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/runpy.py:125: RuntimeWarning: 'pcdet.datasets.kitti.kitti_dataset' found in sys.modules after import of package 'pcdet.datasets.kitti', but prior to execution of 'pcdet.datasets.kitti.kitti_dataset'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
---------------Start to generate data infos---------------
train sample_idx: 000000
train sample_idx: 000003
train sample_idx: 000007
train sample_idx: 000009
train sample_idx: 000010
train sample_idx: 000011
train sample_idx: 000012
train sample_idx: 000013
train sample_idx: 000014
train sample_idx: 000016
train sample_idx: 000017
···
gt_database sample: 3709/3712
gt_database sample: 3710/3712
gt_database sample: 3711/3712
gt_database sample: 3712/3712
Database Pedestrian: 2207
Database Car: 14357
Database Cyclist: 734
Database Van: 1297
Database Truck: 488
Database Tram: 224
Database Misc: 337
Database Person_sitting: 56
---------------Data preparation Done---------------
</code></pre>
<p><br />
代码运行结束后，发现在kitti数据集路径<code>/home/share/nanyang/Kitti</code>下面多了几个文件，此时数据集由以下部分组成：</p>
<pre><code class="language-shell">├── Kitti
│   │── ImageSets
│   │   ├── train.txt &amp; test.txt &amp; val.txt
│   │── training
│   │   ├── calib &amp; velodyne &amp; label_2 &amp; image_2 &amp; (optional: planes)
│   │── testing
│   │   ├── calib &amp; velodyne &amp; image_2
│   │── gt_database
│   │   ├── 000000_Pedestrian_0.bin
│   │   ├── ···
│   │── kitti_dbinfos_train.pkl
│   │── kitti_infos_test.pkl
│   │── kitti_infos_train.pkl
│   │── kitti_infos_trainval.pkl
│   │── kitti_infos_val.pkl
</code></pre>
<h2><a id="8-train" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>8 Train</h2>
<p>此时最激动人心的时刻要来了，首先对部分代码做以下修改：</p>
<pre><code class="language-shell"># modify_path: home/workspace/nanyang/CT3D/tools/cfgs/dataset_configs/kitti_dataset.yaml (line 2)

# 原始代码
DATA_PATH: '../data/kitti'

# 修改后代码
DATA_PATH: '../../../../share/nanyang/Kitti'
</code></pre>
<p><br />
这样kitti数据集的位置正确的修改为<code>/home/share/nanyang/Kitti</code>。接着在<code>/home/workspace/nanyang/CT3D/tools</code>路径下运行以下命令：</p>
<pre><code class="language-shell">$ python train.py --cfg_file /home/workspace/nanyang/CT3D/tools/cfgs/kitti_models/second_ct3d.yaml 
</code></pre>
<p><br />
输出如下：</p>
<pre><code class="language-shell">2024-04-18 11:19:01,163   INFO  **********************Start logging**********************
2024-04-18 11:19:01,163   INFO  CUDA_VISIBLE_DEVICES=1,2,6,7
2024-04-18 11:19:01,163   INFO  cfg_file         ./cfgs/kitti_models/second_ct3d.yaml
2024-04-18 11:19:01,163   INFO  batch_size       1
2024-04-18 11:19:01,163   INFO  epochs           1
2024-04-18 11:19:01,163   INFO  workers          0
2024-04-18 11:19:01,163   INFO  extra_tag        default
2024-04-18 11:19:01,164   INFO  ckpt             None
2024-04-18 11:19:01,164   INFO  pretrained_model None
2024-04-18 11:19:01,164   INFO  launcher         none
2024-04-18 11:19:01,164   INFO  tcp_port         18887
2024-04-18 11:19:01,164   INFO  sync_bn          False
2024-04-18 11:19:01,164   INFO  fix_random_seed  False
2024-04-18 11:19:01,164   INFO  ckpt_save_interval 1
2024-04-18 11:19:01,164   INFO  local_rank       0
2024-04-18 11:19:01,164   INFO  max_ckpt_save_num 30
2024-04-18 11:19:01,164   INFO  merge_all_iters_to_one_epoch False
2024-04-18 11:19:01,164   INFO  set_cfgs         None
2024-04-18 11:19:01,164   INFO  max_waiting_mins 0
2024-04-18 11:19:01,164   INFO  start_epoch      0
2024-04-18 11:19:01,164   INFO  save_to_file     False
2024-04-18 11:19:01,164   INFO  cfg.ROOT_DIR: /home/workspace/nanyang/CT3D
2024-04-18 11:19:01,164   INFO  cfg.LOCAL_RANK: 0
2024-04-18 11:19:01,164   INFO  cfg.CLASS_NAMES: ['Car']
2024-04-18 11:19:01,164   INFO  
cfg.DATA_CONFIG = edict()
2024-04-18 11:19:01,164   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.DATA_PATH: ../../../../share/nanyang/Kitti
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 70.4, 40, 1]
2024-04-18 11:19:01,165   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2024-04-18 11:19:01,165   INFO  
cfg.DATA_CONFIG.INFO_PATH = edict()
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2024-04-18 11:19:01,165   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]
2024-04-18 11:19:01,165   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.05, 0.05, 0.1], 'MAX_POINTS_PER_VOXEL': 5, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]
2024-04-18 11:19:01,165   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml
2024-04-18 11:19:01,166   INFO  
cfg.MODEL = edict()
2024-04-18 11:19:01,166   INFO  cfg.MODEL.NAME: CT3D
2024-04-18 11:19:01,166   INFO  
cfg.MODEL.VFE = edict()
2024-04-18 11:19:01,166   INFO  cfg.MODEL.VFE.NAME: MeanVFE
2024-04-18 11:19:01,166   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelBackBone8x
2024-04-18 11:19:01,166   INFO  
cfg.MODEL.MAP_TO_BEV = edict()
2024-04-18 11:19:01,166   INFO  cfg.MODEL.MAP_TO_BEV.NAME: HeightCompression
2024-04-18 11:19:01,166   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 256
2024-04-18 11:19:01,166   INFO  
cfg.MODEL.BACKBONE_2D = edict()
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [5, 5]
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [1, 2]
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [128, 256]
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2]
2024-04-18 11:19:01,166   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [256, 256]
2024-04-18 11:19:01,166   INFO  
cfg.MODEL.DENSE_HEAD = edict()
2024-04-18 11:19:01,166   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle
2024-04-18 11:19:01,166   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 8, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}]
2024-04-18 11:19:01,167   INFO  
cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG = edict()
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder
2024-04-18 11:19:01,167   INFO  
cfg.MODEL.DENSE_HEAD.LOSS_CONFIG = edict()
2024-04-18 11:19:01,167   INFO  
cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2
2024-04-18 11:19:01,167   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2024-04-18 11:19:01,167   INFO  
cfg.MODEL.ROI_HEAD = edict()
2024-04-18 11:19:01,167   INFO  cfg.MODEL.ROI_HEAD.NAME: CT3DHead
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.CLASS_AGNOSTIC: True
2024-04-18 11:19:01,168   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG = edict()
2024-04-18 11:19:01,168   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN = edict()
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_TYPE: nms_gpu
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.MULTI_CLASSES_NMS: False
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_PRE_MAXSIZE: 9000
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_POST_MAXSIZE: 512
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_THRESH: 0.8
2024-04-18 11:19:01,168   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST = edict()
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_TYPE: nms_gpu
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.MULTI_CLASSES_NMS: False
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_PRE_MAXSIZE: 1024
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_POST_MAXSIZE: 100
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_THRESH: 0.7
2024-04-18 11:19:01,168   INFO  
cfg.MODEL.ROI_HEAD.Transformer = edict()
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.Transformer.num_points: 256
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.Transformer.enc_layers: 3
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.Transformer.dec_layers: 1
2024-04-18 11:19:01,168   INFO  cfg.MODEL.ROI_HEAD.Transformer.dim_feedforward: 512
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.Transformer.hidden_dim: 256
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.Transformer.dropout: 0.1
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.Transformer.nheads: 4
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.Transformer.num_queries: 1
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.Transformer.aux_loss: False
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.Transformer.pre_norm: False
2024-04-18 11:19:01,169   INFO  
cfg.MODEL.ROI_HEAD.TARGET_CONFIG = edict()
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.BOX_CODER: ResidualCoder
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.ROI_PER_IMAGE: 128
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.FG_RATIO: 0.5
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.SAMPLE_ROI_BY_EACH_CLASS: True
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_SCORE_TYPE: roi_iou
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_FG_THRESH: 0.75
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH: 0.25
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH_LO: 0.1
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.HARD_BG_RATIO: 0.8
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.REG_FG_THRESH: 0.55
2024-04-18 11:19:01,169   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG = edict()
2024-04-18 11:19:01,169   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CLS_LOSS: BinaryCrossEntropy
2024-04-18 11:19:01,170   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.REG_LOSS: smooth-l1
2024-04-18 11:19:01,170   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CORNER_LOSS_REGULARIZATION: True
2024-04-18 11:19:01,170   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2024-04-18 11:19:01,170   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_cls_weight: 1.0
2024-04-18 11:19:01,170   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_reg_weight: 1.0
2024-04-18 11:19:01,170   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_corner_weight: 1.0
2024-04-18 11:19:01,170   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2024-04-18 11:19:01,170   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.7
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2024-04-18 11:19:01,170   INFO  
cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2024-04-18 11:19:01,170   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2024-04-18 11:19:01,170   INFO  
cfg.OPTIMIZATION = edict()
2024-04-18 11:19:01,170   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 3
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 100
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.LR: 0.001
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2024-04-18 11:19:01,171   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2024-04-18 11:19:01,171   INFO  cfg.TAG: second_ct3d
2024-04-18 11:19:01,171   INFO  cfg.EXP_GROUP_PATH: kitti_models
2024-04-18 11:19:01,507   INFO  Database filter by min points Car: 14357 =&gt; 13532
2024-04-18 11:19:01,554   INFO  Database filter by difficulty Car: 13532 =&gt; 10759
2024-04-18 11:20:04,706   INFO  Loading KITTI dataset
2024-04-18 11:20:04,926   INFO  Total samples for KITTI dataset: 3712
2024-04-18 11:21:13,729   INFO  CT3D(
  (vfe): MeanVFE()
  (backbone_3d): VoxelBackBone8x(
    (conv_input): SparseSequential(
      (0): SubMConv3d()
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv1): SparseSequential(
      (0): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv2): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d()
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (2): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv3): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d()
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (2): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv4): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d()
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (2): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d()
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (map_to_bev_module): HeightCompression()
  (pfe): None
  (backbone_2d): BaseBEVBackbone(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (dense_head): AnchorHeadSingle(
    (cls_loss_func): SigmoidFocalClassificationLoss()
    (reg_loss_func): WeightedSmoothL1Loss()
    (dir_loss_func): WeightedCrossEntropyLoss()
    (conv_cls): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))
    (conv_box): Conv2d(512, 14, kernel_size=(1, 1), stride=(1, 1))
    (conv_dir_cls): Conv2d(512, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (point_head): None
  (roi_head): CT3DHead(
    (proposal_target_layer): ProposalTargetLayer()
    (reg_loss_func): WeightedSmoothL1Loss()
    (up_dimension): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=28, out_features=64, bias=True)
        (1): Linear(in_features=64, out_features=64, bias=True)
        (2): Linear(in_features=64, out_features=256, bias=True)
      )
    )
    (class_embed): Linear(in_features=256, out_features=1, bias=True)
    (bbox_embed): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): Linear(in_features=256, out_features=7, bias=True)
      )
    )
    (query_embed): Embedding(1, 256)
    (transformer): Transformer(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=512, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=512, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=512, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiHeadedAttention(
              (proj): ModuleList(
                (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
                (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
                (2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
              )
              (down_mlp): MLP(
                (layers): ModuleList(
                  (0): Linear(in_features=64, out_features=1, bias=True)
                )
              )
            )
            (linear1): Linear(in_features=256, out_features=512, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=512, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
2024-04-18 11:21:13,731   INFO  **********************Start training kitti_models/second_ct3d(default)**********************
epochs:   0%|                                                                                                                                      | 0/1 [00:00&lt;?, ?it/s
Segmentation fault (core dumped) 
</code></pre>
<p><br />
但是产生段存储错误：</p>
<pre><code class="language-shell">2024-04-18 11:21:13,731   INFO  **********************Start training kitti_models/second_ct3d(default)**********************
epochs:   0%|                                                                                                                                      | 0/1 [00:00&lt;?, ?it/s
Segmentation fault (core dumped) 
</code></pre>
<p>若是采用多卡分布式训练（8张3090），也会显示如下错误：</p>
<pre><code class="language-shell">$ bash scripts/dist_train.sh 8 --cfg_file cfgs/kitti_models/second_ct3d.yaml
+ NGPUS=8
+ PY_ARGS='--cfg_file cfgs/kitti_models/second_ct3d.yaml'
+ python -m torch.distributed.launch --nproc_per_node=8 train.py --launcher pytorch --cfg_file cfgs/kitti_models/second_ct3d.yaml
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2024-05-03 13:21:36,503   INFO  **********************Start logging**********************
2024-05-03 13:21:36,503   INFO  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
2024-05-03 13:21:36,503   INFO  total_batch_size: 8
2024-05-03 13:21:36,503   INFO  cfg_file         cfgs/kitti_models/second_ct3d.yaml
2024-05-03 13:21:36,503   INFO  batch_size       1
2024-05-03 13:21:36,503   INFO  epochs           100
2024-05-03 13:21:36,503   INFO  workers          0
2024-05-03 13:21:36,503   INFO  extra_tag        default
2024-05-03 13:21:36,504   INFO  ckpt             None
2024-05-03 13:21:36,504   INFO  pretrained_model None
2024-05-03 13:21:36,504   INFO  launcher         pytorch
2024-05-03 13:21:36,504   INFO  tcp_port         18887
2024-05-03 13:21:36,504   INFO  sync_bn          False
2024-05-03 13:21:36,504   INFO  fix_random_seed  False
2024-05-03 13:21:36,504   INFO  ckpt_save_interval 1
2024-05-03 13:21:36,504   INFO  local_rank       0
2024-05-03 13:21:36,504   INFO  max_ckpt_save_num 30
2024-05-03 13:21:36,504   INFO  merge_all_iters_to_one_epoch False
2024-05-03 13:21:36,504   INFO  set_cfgs         None
2024-05-03 13:21:36,504   INFO  max_waiting_mins 0
2024-05-03 13:21:36,504   INFO  start_epoch      0
2024-05-03 13:21:36,504   INFO  save_to_file     False
2024-05-03 13:21:36,504   INFO  cfg.ROOT_DIR: /home/workspace/nanyang/CT3D
2024-05-03 13:21:36,504   INFO  cfg.LOCAL_RANK: 0
2024-05-03 13:21:36,504   INFO  cfg.CLASS_NAMES: ['Car']
2024-05-03 13:21:36,504   INFO  
cfg.DATA_CONFIG = edict()
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.DATASET: KittiDataset
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.DATA_PATH: ../../../../share/nanyang/Kitti
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [0, -40, -3, 70.4, 40, 1]
2024-05-03 13:21:36,505   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2024-05-03 13:21:36,505   INFO  
cfg.DATA_CONFIG.INFO_PATH = edict()
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['kitti_infos_train.pkl']
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['kitti_infos_val.pkl']
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.FOV_POINTS_ONLY: True
2024-05-03 13:21:36,505   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': True, 'DB_INFO_PATH': ['kitti_dbinfos_train.pkl'], 'PREPARE': {'filter_by_min_points': ['Car:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Car:15'], 'NUM_POINT_FEATURES': 4, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': False}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]
2024-05-03 13:21:36,505   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2024-05-03 13:21:36,505   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity']
2024-05-03 13:21:36,506   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity']
2024-05-03 13:21:36,506   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': False}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.05, 0.05, 0.1], 'MAX_POINTS_PER_VOXEL': 5, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]
2024-05-03 13:21:36,506   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml
2024-05-03 13:21:36,506   INFO  
cfg.MODEL = edict()
2024-05-03 13:21:36,506   INFO  cfg.MODEL.NAME: CT3D
2024-05-03 13:21:36,506   INFO  
cfg.MODEL.VFE = edict()
2024-05-03 13:21:36,506   INFO  cfg.MODEL.VFE.NAME: MeanVFE
2024-05-03 13:21:36,506   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelBackBone8x
2024-05-03 13:21:36,506   INFO  
cfg.MODEL.MAP_TO_BEV = edict()
2024-05-03 13:21:36,506   INFO  cfg.MODEL.MAP_TO_BEV.NAME: HeightCompression
2024-05-03 13:21:36,506   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 256
2024-05-03 13:21:36,506   INFO  
cfg.MODEL.BACKBONE_2D = edict()
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackbone
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [5, 5]
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [1, 2]
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [128, 256]
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2]
2024-05-03 13:21:36,506   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [256, 256]
2024-05-03 13:21:36,507   INFO  
cfg.MODEL.DENSE_HEAD = edict()
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.NAME: AnchorHeadSingle
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.USE_DIRECTION_CLASSIFIER: True
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.DIR_OFFSET: 0.78539
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.DIR_LIMIT_OFFSET: 0.0
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.NUM_DIR_BINS: 2
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG: [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 8, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}]
2024-05-03 13:21:36,507   INFO  
cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG = edict()
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NAME: AxisAlignedTargetAssigner
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.POS_FRACTION: -1.0
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.SAMPLE_SIZE: 512
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NORM_BY_NUM_EXAMPLES: False
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MATCH_HEIGHT: False
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.BOX_CODER: ResidualCoder
2024-05-03 13:21:36,507   INFO  
cfg.MODEL.DENSE_HEAD.LOSS_CONFIG = edict()
2024-05-03 13:21:36,507   INFO  
cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2024-05-03 13:21:36,507   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 2.0
2024-05-03 13:21:36,508   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.dir_weight: 0.2
2024-05-03 13:21:36,508   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2024-05-03 13:21:36,508   INFO  
cfg.MODEL.ROI_HEAD = edict()
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NAME: CT3DHead
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.CLASS_AGNOSTIC: True
2024-05-03 13:21:36,508   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG = edict()
2024-05-03 13:21:36,508   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN = edict()
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_TYPE: nms_gpu
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.MULTI_CLASSES_NMS: False
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_PRE_MAXSIZE: 9000
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_POST_MAXSIZE: 512
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TRAIN.NMS_THRESH: 0.8
2024-05-03 13:21:36,508   INFO  
cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST = edict()
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_TYPE: nms_gpu
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.MULTI_CLASSES_NMS: False
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_PRE_MAXSIZE: 1024
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_POST_MAXSIZE: 100
2024-05-03 13:21:36,508   INFO  cfg.MODEL.ROI_HEAD.NMS_CONFIG.TEST.NMS_THRESH: 0.7
2024-05-03 13:21:36,508   INFO  
cfg.MODEL.ROI_HEAD.Transformer = edict()
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.num_points: 256
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.enc_layers: 3
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.dec_layers: 1
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.dim_feedforward: 512
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.hidden_dim: 256
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.dropout: 0.1
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.nheads: 4
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.num_queries: 1
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.aux_loss: False
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.Transformer.pre_norm: False
2024-05-03 13:21:36,509   INFO  
cfg.MODEL.ROI_HEAD.TARGET_CONFIG = edict()
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.BOX_CODER: ResidualCoder
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.ROI_PER_IMAGE: 128
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.FG_RATIO: 0.5
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.SAMPLE_ROI_BY_EACH_CLASS: True
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_SCORE_TYPE: roi_iou
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_FG_THRESH: 0.75
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH: 0.25
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.CLS_BG_THRESH_LO: 0.1
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.HARD_BG_RATIO: 0.8
2024-05-03 13:21:36,509   INFO  cfg.MODEL.ROI_HEAD.TARGET_CONFIG.REG_FG_THRESH: 0.55
2024-05-03 13:21:36,509   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG = edict()
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CLS_LOSS: BinaryCrossEntropy
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.REG_LOSS: smooth-l1
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.CORNER_LOSS_REGULARIZATION: True
2024-05-03 13:21:36,510   INFO  
cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_cls_weight: 1.0
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_reg_weight: 1.0
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.rcnn_corner_weight: 1.0
2024-05-03 13:21:36,510   INFO  cfg.MODEL.ROI_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
2024-05-03 13:21:36,510   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.7
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2024-05-03 13:21:36,510   INFO  
cfg.MODEL.POST_PROCESSING.NMS_CONFIG = edict()
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: False
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.1
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2024-05-03 13:21:36,510   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2024-05-03 13:21:36,510   INFO  
cfg.OPTIMIZATION = edict()
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 1
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 100
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.LR: 0.001
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2024-05-03 13:21:36,511   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2024-05-03 13:21:36,511   INFO  cfg.TAG: second_ct3d
2024-05-03 13:21:36,511   INFO  cfg.EXP_GROUP_PATH: kitti_models
2024-05-03 13:21:36,784   INFO  Database filter by min points Car: 14357 =&gt; 13532
2024-05-03 13:21:36,808   INFO  Database filter by difficulty Car: 13532 =&gt; 10759
2024-05-03 13:21:36,932   INFO  Loading KITTI dataset
2024-05-03 13:21:37,075   INFO  Total samples for KITTI dataset: 3712
2024-05-03 13:21:37,344   INFO  DistributedDataParallel(
  (module): CT3D(
    (vfe): MeanVFE()
    (backbone_3d): VoxelBackBone8x(
      (conv_input): SparseSequential(
        (0): SubMConv3d()
        (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (conv1): SparseSequential(
        (0): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
      (conv2): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d()
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (2): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
      (conv3): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d()
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (2): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
      (conv4): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d()
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (2): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
      (conv_out): SparseSequential(
        (0): SparseConv3d()
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (map_to_bev_module): HeightCompression()
    (pfe): None
    (backbone_2d): BaseBEVBackbone(
      (blocks): ModuleList(
        (0): Sequential(
          (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
          (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (6): ReLU()
          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (9): ReLU()
          (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (12): ReLU()
          (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (15): ReLU()
          (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (18): ReLU()
        )
        (1): Sequential(
          (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
          (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (6): ReLU()
          (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (9): ReLU()
          (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (12): ReLU()
          (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (15): ReLU()
          (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (18): ReLU()
        )
      )
      (deblocks): ModuleList(
        (0): Sequential(
          (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Sequential(
          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
    )
    (dense_head): AnchorHeadSingle(
      (cls_loss_func): SigmoidFocalClassificationLoss()
      (reg_loss_func): WeightedSmoothL1Loss()
      (dir_loss_func): WeightedCrossEntropyLoss()
      (conv_cls): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))
      (conv_box): Conv2d(512, 14, kernel_size=(1, 1), stride=(1, 1))
      (conv_dir_cls): Conv2d(512, 4, kernel_size=(1, 1), stride=(1, 1))
    )
    (point_head): None
    (roi_head): CT3DHead(
      (proposal_target_layer): ProposalTargetLayer()
      (reg_loss_func): WeightedSmoothL1Loss()
      (up_dimension): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=64, bias=True)
          (1): Linear(in_features=64, out_features=64, bias=True)
          (2): Linear(in_features=64, out_features=256, bias=True)
        )
      )
      (class_embed): Linear(in_features=256, out_features=1, bias=True)
      (bbox_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): Linear(in_features=256, out_features=7, bias=True)
        )
      )
      (query_embed): Embedding(1, 256)
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList(
            (0): TransformerEncoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=512, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=512, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerEncoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=512, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=512, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerEncoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=512, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=512, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiHeadedAttention(
                (proj): ModuleList(
                  (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
                  (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
                  (2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
                )
                (down_mlp): MLP(
                  (layers): ModuleList(
                    (0): Linear(in_features=64, out_features=1, bias=True)
                  )
                )
              )
              (linear1): Linear(in_features=256, out_features=512, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=512, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
)
2024-05-03 13:21:37,347   INFO  **********************Start training kitti_models/second_ct3d(default)**********************
epochs:   0%|                                                                                                                                    | 0/100 [00:00&lt;?, ?it/s]/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 4 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
Traceback (most recent call last):
  File &quot;/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/runpy.py&quot;, line 193, in _run_module_as_main
    &quot;__main__&quot;, mod_spec)
  File &quot;/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/runpy.py&quot;, line 85, in _run_code
    exec(code, run_globals)
  File &quot;/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/site-packages/torch/distributed/launch.py&quot;, line 260, in &lt;module&gt;
    main()
  File &quot;/home/workspace/nanyang/anaconda3/envs/ct3d/lib/python3.7/site-packages/torch/distributed/launch.py&quot;, line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/workspace/nanyang/anaconda3/envs/ct3d/bin/python', '-u', 'train.py', '--local_rank=7', '--launcher', 'pytorch', '--cfg_file', 'cfgs/kitti_models/second_ct3d.yaml']' died with &lt;Signals.SIGSEGV: 11&gt;.
</code></pre>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script>!function(){if("undefined"!=typeof Prism&&"undefined"!=typeof document){var e=[],t={},n=function(){};Prism.plugins.toolbar={};var a=Prism.plugins.toolbar.registerButton=function(n,a){var r;r="function"==typeof a?a:function(e){var t;return"function"==typeof a.onClick?((t=document.createElement("button")).type="button",t.addEventListener("click",(function(){a.onClick.call(this,e)}))):"string"==typeof a.url?(t=document.createElement("a")).href=a.url:t=document.createElement("span"),a.className&&t.classList.add(a.className),t.textContent=a.text,t},n in t?console.warn('There is a button with the key "'+n+'" registered already.'):e.push(t[n]=r)},r=Prism.plugins.toolbar.hook=function(a){var r=a.element.parentNode;var l=a.element.classList;if(l.contains('language-mermaid') || l.contains('language-echarts') || l.contains('language-plantuml')){return;} if(r&&/pre/i.test(r.nodeName)&&!r.parentNode.classList.contains("code-toolbar")){var o=document.createElement("div");o.classList.add("code-toolbar"),r.parentNode.insertBefore(o,r),o.appendChild(r);var i=document.createElement("div");i.classList.add("toolbar");var l=e,d=function(e){for(;e;){var t=e.getAttribute("data-toolbar-order");if(null!=t)return(t=t.trim()).length?t.split(/\s*,\s*/g):[];e=e.parentElement}}(a.element);d&&(l=d.map((function(e){return t[e]||n}))),l.forEach((function(e){var t=e(a);if(t){var n=document.createElement("div");n.classList.add("toolbar-item"),n.appendChild(t),i.appendChild(n)}})),o.appendChild(i)}};a("label",(function(e){var t=e.element.parentNode;if(t&&/pre/i.test(t.nodeName)&&t.hasAttribute("data-label")){var n,a,r=t.getAttribute("data-label");try{a=document.querySelector("template#"+r)}catch(e){}return a?n=a.content:(t.hasAttribute("data-url")?(n=document.createElement("a")).href=t.getAttribute("data-url"):n=document.createElement("span"),n.textContent=r),n}})),Prism.hooks.add("complete",r)}}();</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/toolbar/prism-toolbar.min.css"><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script><script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script><style>div.code-toolbar > .toolbar > .toolbar-item > a, div.code-toolbar > .toolbar > .toolbar-item > button, div.code-toolbar > .toolbar > .toolbar-item > span {padding: 4px .5em; background: #f5f2f0; background: rgba(224, 224, 224, 0.4);}</style>


  
    




  </body>
</html>
