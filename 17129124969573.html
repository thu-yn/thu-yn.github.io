<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    SECOND: Sparsely Embedded Convolutional Detection - Prepare for the FUTURE
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="Prepare for the FUTURE" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            SECOND: Sparsely Embedded Convolutional Detection   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2024/04/12</span>
                                  
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_Auxiliary.html'>#Auxiliary</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <blockquote>
<p>选择它的原因：在 CT3D 中作为 RPN 的 backbone</p>
</blockquote>
<h2><a id="1-advantages" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Advantages</h2>
<ol>
<li>在点云目标检测上应用稀疏卷积，并对其改进，大大提高速度；</li>
<li>提出一种角度损失回归方法，具有更好的方向回归表现；</li>
<li>提出一种数据增强方法，提高了收敛速度和表现。</li>
</ol>
<h2><a id="2-pipeline" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Pipeline</h2>
<h3><a id="2-1-overview" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1 Overview</h3>
<div style="text-align: center">
<img src="media/17129124969573/4.png"/>
<p>图 1 SECOND Pipeline</p>
</div>
<p><a href="https://zhuanlan.zhihu.com/p/356892010" title="SECOND">SECOND</a> 由三个部分构成：基于体素的特征提取器；稀疏卷积中间层；RPN 网络。</p>
<p>SECOND 以原始点云作为输入，将其转化为体素的特征和坐标，通过两个 VFE（体素特征编码）层和一个线性层进行特征提取；接着通过稀疏 CNN 层；最后通过 RPN 生成检测。</p>
<h3><a id="2-2-point-cloud-grouping" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2 Point Cloud Grouping</h3>
<ol>
<li>根据体素的数量限制来预分配缓冲区；</li>
<li>迭代点云，将点云中的点分配给他们相关的体素（通过 Hash 表判断是否应该新加体素，或者放到已有体素中），并记录体素的坐标以及体素内点云数量；</li>
<li>当体素数量达到阈值时，停止迭代。获得每个体素的坐标以及其中点云的数量。</li>
<li>根据需要提取的目标的维度特征信息，对点云进行裁剪。裁剪区域需要根据体素大小稍微调整，以确保生成的特征图的大小可以在后续网络中正确下采样。</li>
</ol>
<h3><a id="2-3-voxelwise-feature-extractor" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.3 Voxelwise Feature Extractor</h3>
<p>体素特征提取器由多个 VFE 层和一个 FCN 层构成。</p>
<div style="text-align: center">
<img src="media/17129124969573/6.png"/>
<p>图 2 VFE Pipeline</p>
</div>
<p>采用 <a href="https://arxiv.org/pdf/1711.06396.pdf" title="VAE">VFE</a>（体素特征编码层）对体素内的点云进行特征提取。</p>
<div style="text-align: center">
<img src="media/17129124969573/5.png"/>
<p>图 3 VFE Layer Pipeline</p>
</div>
<p>VFE 将某一体素内的所有点统一作为输入，使用由线性层、\(BatchNorm\) 层和 \(ReLU\) 层组成的 FCN（全连接）层来提取点云特征；接着使用元素最大池化来获得每个体素的局部聚合特征；最后将局部聚合特征平铺，并与点云特征相连接。</p>
<p>定义 \( V=\{p_i=[x_i,y_i,z_i,r_i]^T \in \mathbb{R}^4 \}_{i=1,...,t}\) 为一个包含 t 个点云的非空体素，其中 \( p_i\) 包含了第 \(i\) 个点云的 \(XYZ\) 坐标和其反射强度 \(r_i\)。对该体素 \(V\) 进行体素编码特征的具体流程如下：</p>
<ol>
<li>计算局部均值 \((v_x,v_y,v_z)\) 作为 \(V\) 中所有点的质心；</li>
<li>通过将相对偏移量加入到 \(p_i\) 表示中以补充每个点云表示，并得到输入特征集 \( V_{in}=\{\hat{p_i}=[x_i,y_i,z_i,r_i,x_i-v_x,y_i-v_y,z_i-v_z]^T \in \mathbb{R}^7 \}_{i=1,...,t}\)；</li>
<li>将 \(V\) 中每个 \(\hat{p_i}\) 通过 FCN 网络，通过聚合来自点特征 \(f_i \in R^m\) 的信息来编码体素内物体表面的形状。</li>
<li>在得到点特征表示 \(f_i\) 后，对 \(V\) 中所有 \(f_i\) 采用元素最大池化来得到 \(V\) 的局部特征 \(\tilde{f} \in \mathbb{R}^m\)；</li>
<li>将 \(\tilde{f}\) 补充到每个点云特征 \(f_i\) 中，形成逐点连接特征 \(f^{out}_{i}=[f^T_i,\tilde{f}^T]^T \in \mathbb{R}^{2m}\)，并得到输出特征集合 \( V_{out} = \{f^{out}_{i}\}_{i...t}\)。</li>
</ol>
<p>由于输出特征结合了逐点特征和局部聚合特征，因此堆叠 VFE 层对体素内的点交互进行编码，并使最终特征表示能够学习描述性形状信息。需要注意的是，所有非空体素在编码过程中的 FCN 中的参数都是共享的。</p>
<h3><a id="2-4-sparse-convolutional-middle-extractor" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.4 Sparse Convolutional Middle Extractor</h3>
<h4><a id="2-4-1-sparse-convolution-algorithm-2" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.4.1 <a href="https://zhuanlan.zhihu.com/p/382365889" title="Sparse Convolution Algorithm">Sparse Convolution Algorithm</a></h4>
<p>首先思考 2D 稠密卷积算法。用 \(W_{u,v,l,m}\) 表示过滤后的元素，\(D_{u,v,l}\) 表示图像元素。其中 \(u 和 v\) 是空间位置索引，\(l\) 表示输入通道，\(m\) 表示输出通道。函数 \(P(x,y)\) 根据输出位置索引 \(x 和 y\) 生成输入空间索引 \(u 和 v\)。卷积输出 \(Y_{x,y,m}\) 由以下公式给出：</p>
<p>\( \begin{align}  Y_{x,y,m}=\sum_{u,v \in P_{(x,y)}} \sum_{l} W_{u-u_0,v-v_0,l,m} D_{u,v,l} \end{align}\)</p>
<p>其中 \( u-u_0 和 v-v_0\) 分别表示加上内核偏移量的 \(u 和 v\) 坐标。通过基于 <a href="https://no5-aaron-wu.github.io/2021/12/09/AI-Algorithm-12-GEMM/" title="GEMM">GEMM</a>（通用矩阵乘法）的算法可以得到 \(\tilde{D}_{P(x,y),l}\) 所需的全部数据，接着使用 GEMM 得到 \(Y_{x,y,m}\):</p>
<p>\( \begin{align}  Y_{x,y,m}=\sum_{l} W_{*,l,m} \tilde{D}_{P(x,y),l} \end{align}\)</p>
<p>这里 \(W_{*,l,m}\) 是 \(W_{u-u_0,v-v_0,l,m} \) 的 GEMM 形式。对于稀疏数据 \(D'_{i,l}\) 和相关输出 \( Y'_{j,m}\)，直接计算如下：</p>
<p>\( \begin{align}  Y'_{j,m}=\sum_{i \in P'(j)}\sum_{l} W_{k,l,m} D'_{i,l} \end{align}\)</p>
<p>这里 \(P'(j)\) 是用于获取输入索引 \(i\) 和滤波器偏移量的函数。下标 \(k\) 代表 \( u-u_0 和 v-v_0\)，下标 \(i\) 代表 \(u 和 v\)。式 3 的 GEMM 形式如下：</p>
<p>\( \begin{align}  Y'_{j,m}=\sum_{l} W_{*,l,m} \tilde{D}'_{P'(j),l} \end{align}\)</p>
<p>所收集的稀疏数据矩阵 \(\tilde{D}'_{P'(j),l}\) 仍然包含许多不需要计算的零。因此将式 3 重写如下：</p>
<p>\( \begin{align}  Y'_{j,m}=\sum_{k}\sum_{l} W_{k,l,m} \tilde{D}'_{R_{k,j},k,l} \end{align}\)</p>
<p>这里 \(R_{k,j}\) 是一个 Rule 矩阵，指定给定内核偏移量 \(k\) 的输入索引 \(i\) 和输出索引 \(j\)。由于式 5 中的内和无法用 GEMM 计算，因此我们需要 gather 数据以构造适合 GEMM 计算的矩阵，在计算后再将数据 scatter。</p>
<p>在实践中，可以使用预先构造的输入输出索引 Rule 矩阵从原始稀疏数据中进行 gather 操作，从而加快速度。构建维度为 \(K \times N_{in} \times 2\) 的规则矩阵表 \( R_{k,i,t}=R[k,i,t]\)，其中 \(K\) 是核大小，\(N_{in}\) 是输入特征的数量，\(t\) 是输入和输出的索引。\(R[:,:,0]\) 储存了用于 gather 的输入索引，\(R[:,:,1]\) 储存了用于 scatter 的输出索引。</p>
<div style="text-align: center">
<img src="media/17129124969573/8.png"/>
<p>图 4 Sparse Convolution Algorithm(above) and the GPU Rule Generation Algorithm(below)</p>
</div>
<h4><a id="2-4-2-rule-generation-algorithm" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.4.2 Rule Generation Algorithm</h4>
<p>规则生成的直接方法是迭代输入点以查找与每个输入点相关的输出，并将相应的索引存储到规则中。 在迭代过程中，需要一个表来检查每个输出位置是否存在，以决定是否使用全局输出索引计数器来累积数据。</p>
<div style="text-align: center">
<img src="media/17129124969573/10.png"/>
<p>图 5 Rule Generation Algorithm</p>
</div>
<p>设计的算法如下：</p>
<ol>
<li>首先收集输入索引和与其相关的空间索引，而非输入索引和输出索引，在其阶段获得重复的输出位置；</li>
<li>对空间索引数据执行独特的并行算法，获得输出索引和其相关的空间索引；</li>
<li>根据之前结果生成与稀疏数据具有相同空间维度的缓冲区，用于下一步的表查找；</li>
<li>迭代规则并使用存储的空间索引来获取每个输入索引的输出索引。</li>
</ol>
<div style="text-align: center">
<img src="media/17129124969573/9.png"/>
<p>Alg.1 3D Rule Generation</p>
</div>
<h4><a id="2-4-3-sparse-convolutional-middle-extractor" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.4.3 Sparse Convolutional Middle Extractor</h4>
<p>中间提取器用于学习有关 z 轴的信息并将稀疏 3D 数据转换为 2D BEV 图像。其结构由稀疏卷积的两个阶段组成。 每个阶段包含多个子流形卷积层和一个普通稀疏卷积，用于在 z 轴上执行下采样。 将 z 维下采样到一维或二维后，稀疏数据将转换为密集特征图。 然后，数据被简单地重新整形为类似图像的二维数据。</p>
<div style="text-align: center">
<img src="media/17129124969573/11.png"/>
<p>图 6 Sparse middle feature extractor</p>
</div>
<p>其中白色框代表子流形卷积，黄色框代表稀疏卷积，红色框代表 sparse-to-dense 层。</p>
<h4><a id="2-4-4-region-proposal-network-4" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.4.4 <a href="https://chillstepp.github.io/2021/07/18/RPN-Region-Proposal-Network-%E4%BB%8B%E7%BB%8D/" title="RPN">Region Proposal Network</a></h4>
<p>使用类似 <a href="https://arxiv.org/pdf/1512.02325.pdf%22source%22" title="SSD">SSD</a>（单次多盒检测器）来构建 RPN 架构。 RPN 的输入由稀疏卷积中间提取器的特征图组成。 RPN 架构由三个阶段组成。 每个阶段都从下采样卷积层开始，然后是几个卷积层。 在每个卷积层之后，应用 BatchNorm 和 ReLU 层。 然后，我们将每个阶段的输出上采样为相同大小的特征图，并将这些特征图连接成一个特征图。 最后，应用三个 1 × 1 卷积来预测类别、回归偏移量和方向。</p>
<div style="text-align: center">
<img src="media/17129124969573/12.png"/>
<p>图 7 SSD Pipeline</p>
</div>
<h4><a id="2-4-5-anchors-6-and-targets" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.4.5 <a href="https://zhuanlan.zhihu.com/p/112574936" title="Anchor">Anchors</a> and Targets</h4>
<p>由于要检测的物体大小大致固定，因此我们使用固定大小的锚点，该锚点是根据 KITTI 训练集中所有地面实况的大小和中心位置的平均值确定的，旋转角度为 0 度和 90 度。 对于汽车，我们使用尺寸为 \(w = 1.6 \times l = 3.9 \times h = 1.56 m\) 的锚，中心位于 \(z = −1.0 m\)。 对于行人，我们使用尺寸为 \(w = 0.6 \times l = 0.8 \times h = 1.73 m\) 的锚点，对于骑自行车的人，锚点的尺寸为 \(w = 0.6 \times l = 1.76 \times h = 1.73 m\)； 两者均以 \(z = −0.6 m\) 为中心。</p>
<p>每个锚点都分配有一个分类目标的 one-hot 向量、一个框回归目标的 7 向量和一个方向分类目标的 one-hot 向量。 不同的类别有不同的匹配和不匹配阈值。 对于汽车，锚点使用 0.6 的交并集 (IoU) 阈值分配给地面实况对象，如果 IoU 小于 0.45，则将锚点分配给背景（负）。 IoU 在 0.45 到 0.6 之间的锚点在训练过程中会被忽略。 对于行人和骑自行车的人，我们使用 0.35 作为不匹配阈值，使用 0.5 作为匹配阈值。</p>
<p>对于回归目标，我们使用以下框编码函数：</p>
<p>\( \begin{align}  x_t=\frac {x_g-x_a} {d_a}, y_t=\frac {y_g-y_a} {d_a}, z_t=\frac {z_g-z_a} {h_a} \end{align}\)</p>
<p>\( \begin{align}  w_t=log(\frac {w_g} {w_a}), l_t=log(\frac {l_g} {l_a}), h_t=log(\frac {h_g} {h_a})  \end{align}\)</p>
<p>\( \begin{align}  \theta_t=\theta_g-\theta_a \end{align}\)</p>
<p>其中 \(x、y 和 z\) 是中心坐标； \(w、l、h\) 分别是宽度、长度、高度； \(θ\) 是绕 \(z\) 轴的偏航旋转； 下标\(t、a、g\) 分别表示编码值、anchor、groundtruth； \( d^a = \sqrt{(l^a)^2+(w^a)^2}\) 是锚框底边的对角线。</p>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>

<style>.mweb-charts{background:#fff;}
body{ box-sizing: border-box;
    margin: 0 auto;}
@media print{
    pre, code, pre code {
     overflow: visible !important;
     white-space: pre-wrap !important;       /* css-3 */
     white-space: -moz-pre-wrap !important;  /* Mozilla, since 1999 */
     white-space: -pre-wrap !important;      /* Opera 4-6 */
     white-space: -o-pre-wrap !important;    /* Opera 7 */
     word-wrap: break-word !important;       /* Internet Explorer 5.5+ */
    }
    html,body{margin:0;padding:4px;}
}



div.code-toolbar {
  position: relative;
}

div.code-toolbar > .toolbar {
  position: absolute;
  z-index: 10;
  top: .3em;
  right: .2em;
  transition: opacity 0.3s ease-in-out;
  opacity: 0;
}

div.code-toolbar:hover > .toolbar {
  opacity: 1;
}

/* Separate line b/c rules are thrown out if selector is invalid.
   IE11 and old Edge versions don't support :focus-within. */
div.code-toolbar:focus-within > .toolbar {
  opacity: 1;
}

div.code-toolbar > .toolbar > .toolbar-item {
  display: inline-block;
}

div.code-toolbar > .toolbar > .toolbar-item > a {
  cursor: pointer;
}

div.code-toolbar > .toolbar > .toolbar-item > button {
  background: none;
  border: 0;
  color: inherit;
  font: inherit;
  line-height: normal;
  overflow: visible;
  padding: 0;
  -webkit-user-select: none; /* for button */
  -moz-user-select: none;
  -ms-user-select: none;
}

div.code-toolbar > .toolbar > .toolbar-item > a,
div.code-toolbar > .toolbar > .toolbar-item > button,
div.code-toolbar > .toolbar > .toolbar-item > span {
  color: inherit;
  font-size: .8em;
  padding: 4px .5em;
  background: #f5f2f0;
  background: rgba(224, 224, 224, 0.4);
  box-shadow: 0 2px 0 0 rgba(0,0,0,0.2);
  border-radius: .5em;
}

div.code-toolbar > .toolbar > .toolbar-item > a:hover,
div.code-toolbar > .toolbar > .toolbar-item > a:focus,
div.code-toolbar > .toolbar > .toolbar-item > button:hover,
div.code-toolbar > .toolbar > .toolbar-item > button:focus,
div.code-toolbar > .toolbar > .toolbar-item > span:hover,
div.code-toolbar > .toolbar > .toolbar-item > span:focus {
  color: inherit;
  text-decoration: none;
}
</style><script>window.MathJax = {     tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } ,     startup: {     pageReady() {       return MathJax.startup.defaultPageReady().then(function () {          window.mweb_mathjax_ready_val = 'yes';          if(window.mweb_mathjax_ready !== undefined){ mweb_mathjax_ready(); }       });     }   }};document.addEventListener('DOMContentLoaded', function(event) {    if (typeof Prism != 'undefined') {         Prism.highlightAll();     }});window.mweb_mathjax_ready_val = '';function theMWebMathJaxRenderIsReady(key){ return window.mweb_mathjax_ready_val; }</script><script>window.MathJax = { tex: { packages: {'[+]': ['physics']}, tags: 'all', inlineMath: [ ['$','$'], ['\\(','\\)'] ] },loader: { load: ['[tex]/physics'] } }; </script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>


  
    




  </body>
</html>
